#!/usr/bin/env python3 # /// script # requires-python = ">=3.11" # dependencies = [ # "pyyaml>=6.0", # ] # /// """ Validate annotation quality and consistency. Checks: - Format correctness (JSONL, YAML, JSON) - Duplicate detection - Coverage analysis (test set alignment) - Quality metrics (similarity score distribution, etc.) """ from __future__ import annotations import argparse import json import logging from collections import Counter from pathlib import Path from typing import Any try: import yaml HAS_YAML = True except ImportError: HAS_YAML = False from ml.utils.annotation_utils import load_similarity_annotations from ml.utils.data_loading import load_test_set from ml.utils.paths import PATHS logging.basicConfig(level=logging.INFO) logger = logging.getLogger(__name__) def validate_substitution_pairs(pairs_file: Path) -> dict[str, Any]: """Validate substitution pairs JSON file.""" if not pairs_file.exists(): return {"error": "File not found"} try: pairs = json.load(open(pairs_file)) except Exception as e: return {"error": f"Failed to load: {e}"} issues = [] stats = { "total": len(pairs), "duplicates": 0, "invalid_format": 0, "empty_pairs": 0, "self_pairs": 0, } seen = set() for i, pair in enumerate(pairs): # Check format if not isinstance(pair, list): issues.append(f"Pair {i}: Not a list") stats["invalid_format"] += 1 continue if len(pair) != 2: issues.append(f"Pair {i}: Expected 2 cards, got {len(pair)}") stats["invalid_format"] += 1 continue card1, card2 = pair[0], pair[1] # Check for empty if not card1 or not card2: issues.append(f"Pair {i}: Empty card name") stats["empty_pairs"] += 1 continue # Check for self-pairs if card1 == card2: issues.append(f"Pair {i}: Self-pair ({card1})") stats["self_pairs"] += 1 continue # Check for duplicates key = tuple(sorted([str(card1), str(card2)])) if key in seen: issues.append(f"Pair {i}: Duplicate ({card1}, {card2})") stats["duplicates"] += 1 seen.add(key) return { "valid": len(issues) == 0, "stats": stats, "unique_pairs": len(seen), "issues": issues[:20], # Limit to first 20 } def validate_annotations(annotation_file: Path) -> dict[str, Any]: """Validate similarity annotations (JSONL or YAML).""" if not annotation_file.exists(): return {"error": "File not found"} try: annotations = load_similarity_annotations(annotation_file) except Exception as e: return {"error": f"Failed to load: {e}"} stats = { "total": len(annotations), "with_substitute_flag": 0, "substitute_true": 0, "high_similarity": 0, "duplicates": 0, } similarity_scores = [] seen = set() for ann in annotations: card1 = ann.get("card1", "") card2 = ann.get("card2", "") key = tuple(sorted([card1, card2])) if key in seen: stats["duplicates"] += 1 seen.add(key) if "is_substitute" in ann: stats["with_substitute_flag"] += 1 if ann["is_substitute"]: stats["substitute_true"] += 1 similarity = ann.get("similarity_score", 0.0) if similarity: similarity_scores.append(similarity) if similarity >= 0.8: stats["high_similarity"] += 1 return { "valid": True, "stats": stats, "similarity_distribution": { "min": min(similarity_scores) if similarity_scores else 0.0, "max": max(similarity_scores) if similarity_scores else 0.0, "mean": sum(similarity_scores) / len(similarity_scores) if similarity_scores else 0.0, }, "substitution_rate": stats["substitute_true"] / stats["total"] * 100 if stats["total"] > 0 else 0.0, } def analyze_coverage(pairs_file: Path, test_set_path: Path | None = None) -> dict[str, Any]: """Analyze annotation coverage of test set.""" if not pairs_file.exists(): return {"error": "Pairs file not found"} try: pairs = json.load(open(pairs_file)) except Exception as e: return {"error": f"Failed to load: {e}"} # Get all cards in pairs all_cards = set() for pair in pairs: if isinstance(pair, list) and len(pair) == 2: all_cards.add(pair[0]) all_cards.add(pair[1]) if not test_set_path: test_set_path = PATHS.test_magic else: test_set_path = Path(test_set_path) if not test_set_path.exists(): return {"error": f"Test set not found: {test_set_path}"} try: # Load directly from path (load_test_set has issues with full paths) with open(test_set_path) as f: test_set = json.load(f) queries = test_set.get("queries", {}) except Exception as e: return {"error": f"Failed to load test set: {e}"} # Check query coverage queries_covered = sum(1 for q in queries.keys() if q in all_cards) # Check relevant card coverage total_relevant = 0 relevant_covered = 0 for query, labels in queries.items(): relevant = set(labels.get("highly_relevant", [])) | set(labels.get("relevant", [])) total_relevant += len(relevant) relevant_covered += sum(1 for r in relevant if r in all_cards) return { "pairs_count": len(pairs), "unique_cards": len(all_cards), "test_queries": len(queries), "queries_covered": queries_covered, "query_coverage_pct": queries_covered / len(queries) * 100 if queries else 0.0, "total_relevant": total_relevant, "relevant_covered": relevant_covered, "relevant_coverage_pct": relevant_covered / total_relevant * 100 if total_relevant > 0 else 0.0, } def main() -> int: """Validate annotations.""" parser = argparse.ArgumentParser(description="Validate annotation quality") parser.add_argument("--pairs", type=Path, help="Substitution pairs JSON file") parser.add_argument("--annotations", type=Path, help="Similarity annotations (JSONL/YAML)") parser.add_argument("--test-set", type=Path, help="Test set for coverage analysis") parser.add_argument("--coverage", action="store_true", help="Analyze test set coverage") args = parser.parse_args() if not args.pairs and not args.annotations: parser.error("Must provide --pairs or --annotations") print("=" * 70) print("ANNOTATION VALIDATION") print("=" * 70) print() if args.pairs: print("Validating substitution pairs...") result = validate_substitution_pairs(args.pairs) if "error" in result: print(f"Error: Error: {result['error']}") return 1 print(f" Total pairs: {result['stats']['total']}") print(f" Unique pairs: {result['unique_pairs']}") print(f" Duplicates: {result['stats']['duplicates']}") print(f" Invalid format: {result['stats']['invalid_format']}") print(f" Empty pairs: {result['stats']['empty_pairs']}") print(f" Self-pairs: {result['stats']['self_pairs']}") if result['valid']: print(" All pairs valid") else: print(f" Warning: Found {len(result['issues'])} issues") for issue in result['issues'][:5]: print(f" - {issue}") print() if args.annotations: print("Validating similarity annotations...") result = validate_annotations(args.annotations) if "error" in result: print(f"Error: Error: {result['error']}") return 1 print(f" Total annotations: {result['stats']['total']}") print(f" With is_substitute flag: {result['stats']['with_substitute_flag']}") print(f" is_substitute=True: {result['stats']['substitute_true']}") print(f" Substitution rate: {result['substitution_rate']:.1f}%") print(f" High similarity (>=0.8): {result['stats']['high_similarity']}") print(f" Duplicates: {result['stats']['duplicates']}") if result['similarity_distribution']['mean'] > 0: print(f" Similarity scores: min={result['similarity_distribution']['min']:.2f}, " f"max={result['similarity_distribution']['max']:.2f}, " f"mean={result['similarity_distribution']['mean']:.2f}") print() if args.coverage and args.pairs: print("Analyzing test set coverage...") result = analyze_coverage(args.pairs, args.test_set) if "error" in result: print(f"Error: Error: {result['error']}") return 1 print(f" Pairs: {result['pairs_count']}") print(f" Unique cards: {result['unique_cards']}") print(f" Test queries: {result['test_queries']}") print(f" Queries covered: {result['queries_covered']} ({result['query_coverage_pct']:.1f}%)") print(f" Relevant cards covered: {result['relevant_covered']}/{result['total_relevant']} ({result['relevant_coverage_pct']:.1f}%)") print() print(" Validation complete") return 0 if __name__ == "__main__": import sys sys.exit(main())