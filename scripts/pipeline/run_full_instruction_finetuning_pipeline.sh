#!/usr/bin/env bash # Full pipeline: Prepare data → Fine-tune → Evaluate set -euo pipefail SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)" PROJECT_ROOT="$(cd "$SCRIPT_DIR/.." && pwd)" cd "$PROJECT_ROOT" echo "═══════════════════════════════════════════════════════════════════════" echo "FULL INSTRUCTION EMBEDDING FINE-TUNING PIPELINE" echo "═══════════════════════════════════════════════════════════════════════" echo "" # Step 1: Prepare training data echo "STEP 1: Preparing multi-task training data..." TRAINING_DATA="experiments/instruction_finetuning_data.json" python3 scripts/prepare_instruction_finetuning_data.py --output "$TRAINING_DATA" if [ ! -f "$TRAINING_DATA" ]; then echo "Error: Failed to create training data" exit 1 fi # Step 2: Fine-tune on all tasks echo "" echo "STEP 2: Fine-tuning on all tasks..." echo " (This may take a while - fine-tuning requires GPU for best performance)" echo "" # Check if we should run fine-tuning (requires GPU and sentence-transformers) if command -v python3 &> /dev/null; then python3 -c "import sentence_transformers; import torch; print(' Dependencies available')" 2>/dev/null || { echo "Warning: sentence-transformers or torch not available" echo " Install with: uv add sentence-transformers torch" echo " Skipping fine-tuning step..." SKIP_FINETUNING=1 } else SKIP_FINETUNING=1 fi if [ "${SKIP_FINETUNING:-0}" != "1" ]; then bash scripts/finetune_instruction_embeddings_all_tasks.sh else echo "Warning: Skipping fine-tuning (dependencies not available or user preference)" fi # Step 3: Evaluate zero-shot baseline echo "" echo "STEP 3: Evaluating zero-shot baseline..." python3 scripts/evaluate_instruction_embeddings.py \ --base-model "intfloat/e5-base-v2" \ --test-set "experiments/test_set_unified_magic.json" \ --task-type "substitution" \ --output "experiments/instruction_eval_zero_shot.json" || echo "Warning: Evaluation failed (may need test set)" # Step 4: Compare if fine-tuned models exist if [ -d "data/embeddings/instruction_finetuned" ]; then echo "" echo "STEP 4: Comparing fine-tuned models..." for task_dir in data/embeddings/instruction_finetuned/*/; do if [ -d "$task_dir" ]; then task=$(basename "$task_dir") echo " Evaluating task: $task" python3 scripts/evaluate_instruction_embeddings.py \ --base-model "intfloat/e5-base-v2" \ --fine-tuned "$task_dir" \ --test-set "experiments/test_set_unified_magic.json" \ --task-type "$task" \ --output "experiments/instruction_eval_${task}.json" || echo " Warning: Evaluation failed" fi done fi echo "" echo "═══════════════════════════════════════════════════════════════════════" echo " PIPELINE COMPLETE" echo "═══════════════════════════════════════════════════════════════════════" echo "" echo "Results:" echo " Training data: $TRAINING_DATA" if [ -d "data/embeddings/instruction_finetuned" ]; then echo " Fine-tuned models: data/embeddings/instruction_finetuned/" fi echo " Evaluation results: experiments/instruction_eval_*.json" echo "" echo "Next: Review evaluation results and deploy best model"