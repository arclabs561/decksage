#!/usr/bin/env bash # Evaluate downstream tasks using runctl on AWS for faster execution # # Usage: # ./scripts/evaluation/evaluate_downstream_runctl.sh [--game magic] [--quick] [--instance-id i-xxx] # # Options: # --game: Game to evaluate (magic, pokemon, yugioh) [default: magic] # --quick: Use quick test set (50 pairs) instead of full [default: false] # --instance-id: Use existing instance instead of creating new one # --spot: Use spot instance (default: true) # --output-version: Version tag for output [default: v$(date +%Y-W%V)] set -euo pipefail SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)" PROJECT_ROOT="$(cd "$SCRIPT_DIR/../.." && pwd)" RUNCTL="${PROJECT_ROOT}/../runctl/target/release/runctl" # Check runctl exists if [ ! -f "$RUNCTL" ]; then echo "Error: runctl not found at $RUNCTL" echo "Build it with: cd ../runctl && cargo build --release" exit 1 fi # Default arguments GAME="magic" QUICK=false INSTANCE_ID="" USE_SPOT=true OUTPUT_VERSION="v$(date +%Y-W%V)" # Parse arguments while [[ $# -gt 0 ]]; do case $1 in --game) GAME="$2" shift 2 ;; --quick) QUICK=true shift ;; --instance-id) INSTANCE_ID="$2" shift 2 ;; --spot) USE_SPOT=true shift ;; --no-spot) USE_SPOT=false shift ;; --output-version) OUTPUT_VERSION="$2" shift 2 ;; *) echo "Unknown option: $1" exit 1 ;; esac done # S3 paths DATA_S3="${DATA_S3:-s3://games-collections/}" OUTPUT_S3="${OUTPUT_S3:-s3://games-collections/experiments/}" # Test set paths if [ "$QUICK" == "true" ]; then TEST_SUBSTITUTIONS="experiments/test_substitutions_quick.json" else TEST_SUBSTITUTIONS="experiments/test_set_unified_${GAME}.json" fi # Embeddings path EMBEDDINGS_PATH="data/embeddings/game_specific/${GAME}_128d_test_pecanpy.wv" # Output paths OUTPUT_DIR="experiments/downstream_eval_${GAME}_${OUTPUT_VERSION}" OUTPUT_S3_PATH="${OUTPUT_S3}downstream_eval_${GAME}_${OUTPUT_VERSION}/" echo "═══════════════════════════════════════════════════════════════════════" echo "DOWNSTREAM TASK EVALUATION (runctl on AWS)" echo "═══════════════════════════════════════════════════════════════════════" echo "" echo "Game: $GAME" echo "Quick mode: $QUICK" echo "Output version: $OUTPUT_VERSION" echo "Test set: $TEST_SUBSTITUTIONS" echo "Embeddings: $EMBEDDINGS_PATH" echo "Output S3: $OUTPUT_S3_PATH" echo "" # Create or use existing instance if [ -z "$INSTANCE_ID" ]; then echo "Creating AWS instance..." INSTANCE_TYPE="g5.xlarge" # GPU for faster processing if [ "$USE_SPOT" == "true" ]; then CREATE_OUTPUT=$("$RUNCTL" aws create \ --spot \ --key-name tarek \ --iam-instance-profile EC2-SSM-InstanceProfile \ --data-volume-size 100 \ "$INSTANCE_TYPE" 2>&1) || CREATE_OUTPUT=$("$RUNCTL" aws create \ --key-name tarek \ --iam-instance-profile EC2-SSM-InstanceProfile \ --data-volume-size 100 \ "$INSTANCE_TYPE" 2>&1) else CREATE_OUTPUT=$("$RUNCTL" aws create \ --key-name tarek \ --iam-instance-profile EC2-SSM-InstanceProfile \ --data-volume-size 100 \ "$INSTANCE_TYPE" 2>&1) fi echo "$CREATE_OUTPUT" # Extract instance ID INSTANCE_ID=$(echo "$CREATE_OUTPUT" | grep -iE '(created|instance:).*i-[a-z0-9]+' | grep -oE 'i-[a-z0-9]+' | head -1 || echo "") if [ -z "$INSTANCE_ID" ]; then INSTANCE_ID=$(echo "$CREATE_OUTPUT" | grep -oE 'i-[a-z0-9]{17}' | head -1 || echo "") fi if [ -z "$INSTANCE_ID" ]; then echo "Error: Failed to create instance or extract instance ID" echo "Full output:" echo "$CREATE_OUTPUT" exit 1 fi echo " Created instance: $INSTANCE_ID" echo "Waiting for instance to be ready..." sleep 45 # Give instance time to initialize else echo "Using existing instance: $INSTANCE_ID" fi # Run evaluation on the instance echo "" echo "Submitting evaluation job..." echo "" # Build command arguments EVAL_ARGS=( --game "$GAME" --embeddings "$EMBEDDINGS_PATH" --output "$OUTPUT_DIR/results.json" --fast # Use fast mode (disable expensive operations) ) if [ -n "$TEST_SUBSTITUTIONS" ]; then EVAL_ARGS+=(--test-substitutions "$TEST_SUBSTITUTIONS") fi # Use --pairs to speed up graph loading (CSV is faster than SQLite for large graphs) EVAL_ARGS+=(--pairs "data/processed/pairs_large.csv") # Submit job (runctl will handle instance lifecycle) # runctl syncs code to /home/ec2-user/{project_name}/ by default PROJECT_NAME=$(basename "$PROJECT_ROOT") # Export environment for runctl export TRAINCTL_USE_SHELL_SYNC=1 "$RUNCTL" aws train "$INSTANCE_ID" \ "src/ml/scripts/evaluate_downstream_complete.py" \ --data-s3 "$DATA_S3" \ --output-s3 "$OUTPUT_S3" \ --project-name "$PROJECT_NAME" \ -- \ "${EVAL_ARGS[@]}" echo "" echo "═══════════════════════════════════════════════════════════════════════" echo " EVALUATION JOB SUBMITTED" echo "═══════════════════════════════════════════════════════════════════════" echo "" echo "Instance: $INSTANCE_ID" echo "Output will be saved to:" echo " Local: $OUTPUT_DIR/results.json" echo " S3: $OUTPUT_S3_PATH" echo "" echo "Monitor with:" echo " $RUNCTL aws monitor $INSTANCE_ID" echo "" echo "Or check S3:" echo " aws s3 ls $OUTPUT_S3_PATH" echo "" echo "Note: Instance will continue running after evaluation." echo "Stop manually with: $RUNCTL aws stop $INSTANCE_ID"
