#!/bin/bash # Comprehensive dataset statistics using s5cmd for speed set -euo pipefail BUCKET="s3://games-collections" echo "======================================================================" echo "DECK SAGE DATASET STATISTICS" echo "======================================================================" echo "" # Check s5cmd if ! command -v s5cmd &> /dev/null; then echo "Warning: s5cmd not found. Install: https://github.com/peak/s5cmd" echo " Falling back to aws cli (slower)..." USE_S5CMD=false else USE_S5CMD=true fi # S3 Dataset counts echo " S3 Dataset Inventory (games/):" echo "----------------------------------------------------------------------" if [[ "$USE_S5CMD" == "true" ]]; then s5cmd ls "$BUCKET/games/" 2>&1 | \ awk '{print $NF}' | \ sed 's|s3://games-collections/games/||' | \ cut -d'/' -f1-2 | \ sort | uniq -c | sort -rn | \ head -30 | \ awk '{printf " %-50s %8s files\n", $2, $1}' else aws s3 ls "$BUCKET/games/" --recursive 2>&1 | \ awk '{print $4}' | \ sed 's|games/||' | \ cut -d'/' -f1-2 | \ sort | uniq -c | sort -rn | \ head -30 | \ awk '{printf " %-50s %8s files\n", $2, $1}' fi echo "" # Local processed data echo " Local Processed Data:" echo "----------------------------------------------------------------------" if [[ -d "data/processed" ]]; then for file in data/processed/*.csv data/processed/*.jsonl; do [[ -f "$file" ]] || continue lines=$(wc -l < "$file" 2>/dev/null | tr -d ' ' || echo "0") size=$(du -h "$file" 2>/dev/null | cut -f1 || echo "?") printf " %-40s %10s lines %8s\n" "$(basename "$file")" "$lines" "$size" done else echo " Warning: data/processed/ not found" fi echo "" # Graph stats echo " Incremental Graph:" echo "----------------------------------------------------------------------" if [[ -f "data/graphs/incremental_graph.db" ]]; then python3 << 'PYEOF' import sqlite3 from pathlib import Path graph_db = Path("data/graphs/incremental_graph.db") if graph_db.exists(): conn = sqlite3.connect(str(graph_db)) cursor = conn.cursor() try: cursor.execute("SELECT COUNT(*) FROM nodes") nodes = cursor.fetchone()[0] print(f" Nodes: {nodes:,}") except: pass try: cursor.execute("SELECT COUNT(*) FROM edges") edges = cursor.fetchone()[0] print(f" Edges: {edges:,}") except: pass try: cursor.execute("SELECT value FROM metadata WHERE key='total_decks_processed'") result = cursor.fetchone() if result: print(f" Decks: {int(result[0]):,}") except: pass size_gb = graph_db.stat().st_size / (1024**3) print(f" Size: {size_gb:.2f} GB") conn.close() else: print(" Warning: Graph DB not found") PYEOF else echo " Warning: Graph DB not found" fi echo "" # Embeddings echo " Embeddings:" echo "----------------------------------------------------------------------" if [[ -d "data/embeddings" ]]; then for emb in data/embeddings/*.wv data/embeddings/*.json; do [[ -f "$emb" ]] || continue size=$(du -h "$emb" 2>/dev/null | cut -f1 || echo "?") printf " %-50s %8s\n" "$(basename "$emb")" "$size" done | head -15 else echo " Warning: data/embeddings/ not found" fi echo "" # Test sets echo " Test Sets:" echo "----------------------------------------------------------------------" if [[ -d "experiments" ]]; then for test in experiments/test_set*.json; do [[ -f "$test" ]] || continue size=$(du -h "$test" 2>/dev/null | cut -f1 || echo "?") printf " %-50s %8s\n" "$(basename "$test")" "$size" done else echo " Warning: experiments/ not found" fi echo "" echo "======================================================================" echo "STATISTICS COMPLETE" echo "======================================================================"
