#!/usr/bin/env python3 # /// script # requires-python = ">=3.11" # dependencies = [] # /// """ Generate co-occurrence pairs from exported deck files. Addresses Priority 1 from DATA_COVERAGE_CRITIQUE.md - generate pairs for all games. DATA LINEAGE: Order 2 (depends on Order 1: Exported Decks) - Input: data/processed/decks_{game}_{source}.jsonl (Order 1) - Output: data/processed/pairs_{game}_{source}.csv (Order 2) - Can be regenerated from Order 1 data """ import argparse import csv import json import sys from collections import defaultdict from pathlib import Path from typing import Any # Add src to path script_dir = Path(__file__).parent src_dir = script_dir.parent.parent / "src" if str(src_dir) not in sys.path: sys.path.insert(0, str(src_dir)) from ml.utils.paths import PATHS def extract_pairs_from_decks( deck_file: Path, output_file: Path, game: str, source: str, ) -> int: """Extract co-occurrence pairs from deck JSONL file.""" if not deck_file.exists(): print(f"Warning: Deck file not found: {deck_file}") return 0 # Count co-occurrences pair_counts: dict[tuple[str, str], int] = defaultdict(int) deck_count = 0 deck_ids = [] print(f"Processing {deck_file}...") with open(deck_file) as f: for line_num, line in enumerate(f, 1): if not line.strip(): continue try: deck = json.loads(line) # Fix: Use proper deck_id from deck metadata deck_id = deck.get("deck_id") or deck.get("id") or f"{source}_{line_num}" deck_ids.append(deck_id) # Extract all cards - handle both formats all_cards = [] # Try cards array first (export-hetero format) if "cards" in deck: for card in deck["cards"]: if isinstance(card, dict): card_name = card.get("name", "") count = card.get("count", 1) else: card_name = str(card) count = 1 if card_name: all_cards.extend([card_name] * count) # Try partitions format (collection format) if "partitions" in deck: for partition in deck["partitions"]: for card in partition.get("cards", []): if isinstance(card, dict): card_name = card.get("name", "") count = card.get("count", 1) else: card_name = str(card) count = 1 if card_name: all_cards.extend([card_name] * count) if not all_cards: continue # Generate pairs (all cards in deck co-occur) for i, card1 in enumerate(all_cards): for card2 in all_cards[i+1:]: # Normalize pair (alphabetical order) pair = tuple(sorted([card1, card2])) pair_counts[pair] += 1 deck_count += 1 if deck_count % 1000 == 0: print(f" Processed {deck_count:,} decks, {len(pair_counts):,} unique pairs...") except json.JSONDecodeError as e: print(f"Warning: Skipping invalid JSON on line {line_num}: {e}") continue if len(pair_counts) == 0: print(f"Warning: No pairs extracted from {deck_file}") return 0 # Write pairs to CSV output_file.parent.mkdir(parents=True, exist_ok=True) print(f"Writing {len(pair_counts):,} unique pairs to {output_file}...") # Use first deck_id as default (for aggregated pairs) default_deck_id = deck_ids[0] if deck_ids else f"{source}_aggregated" with open(output_file, "w", newline="") as f: writer = csv.writer(f) writer.writerow(["NAME_1", "NAME_2", "GAME_1", "GAME_2", "COUNT", "DECK_ID", "SOURCE"]) for (card1, card2), count in sorted(pair_counts.items()): # For aggregated pairs, use default deck_id writer.writerow([card1, card2, game, game, count, default_deck_id, source]) total_pairs = sum(pair_counts.values()) print(f" Generated {total_pairs:,} pairs ({len(pair_counts):,} unique) from {deck_count:,} decks") return total_pairs def main() -> int: parser = argparse.ArgumentParser(description="Generate pairs from exported decks") parser.add_argument("--game", choices=["digimon", "onepiece", "riftbound", "yugioh", "pokemon", "all"], default="all", help="Game to process") parser.add_argument("--input-dir", type=Path, default=PATHS.processed, help="Input directory with deck files") parser.add_argument("--output-dir", type=Path, default=PATHS.processed, help="Output directory for pair files") parser.add_argument("--combine", action="store_true", help="Combine all games into single pairs file") args = parser.parse_args() # Find all deck files deck_files = [] if args.game == "all": patterns = ["decks_*.jsonl"] else: patterns = [f"decks_{args.game}_*.jsonl"] for pattern in patterns: deck_files.extend(args.input_dir.glob(pattern)) if not deck_files: print(f"Warning: No deck files found matching {patterns}") return 1 print("=" * 80) print("GENERATING PAIRS FROM EXPORTED DECKS") print("=" * 80) print() all_pairs = [] total_pairs = 0 for deck_file in sorted(deck_files): # Extract game and source from filename # Format: decks_{game}_{source}.jsonl OR decks_{game}.jsonl stem = deck_file.stem.replace("decks_", "") parts = stem.split("_", 1) if len(parts) == 2: game, source = parts elif len(parts) == 1: # Handle decks_pokemon.jsonl format (no source suffix) game = parts[0] source = "unknown" else: print(f"Warning: Unexpected filename format: {deck_file.name}") continue output_file = args.output_dir / f"pairs_{game}_{source}.csv" count = extract_pairs_from_decks(deck_file, output_file, game, source) total_pairs += count if args.combine: all_pairs.append(output_file) if args.combine and all_pairs: # Combine all pairs into single file combined_file = args.output_dir / "pairs_all_games.csv" print(f"\nCombining all pairs into {combined_file}...") with open(combined_file, "w", newline="") as out: writer = csv.writer(out) writer.writerow(["NAME_1", "NAME_2", "GAME_1", "GAME_2", "COUNT", "DECK_ID", "SOURCE"]) for pair_file in all_pairs: with open(pair_file) as f: reader = csv.reader(f) next(reader) # Skip header for row in reader: writer.writerow(row) print(f" Combined pairs written to {combined_file}") print("\n" + "=" * 80) print(f" Total pairs generated: {total_pairs:,}") print("=" * 80) return 0 if __name__ == "__main__": sys.exit(main())
