#!/usr/bin/env python3 """ Unify test sets across all games by merging the best available sets. Strategy: 1. Identify best test sets for each game (largest, most complete) 2. Merge them intelligently (deduplicate queries, preserve best labels) 3. Create unified canonical sets 4. Sync to S3 """ import json import sys from collections import defaultdict from pathlib import Path from typing import Any def load_test_set(path: Path) -> dict[str, Any] | None: """Load test set from JSON.""" try: with open(path, 'rb') as f: return json.load(f) except Exception as e: print(f"ERROR: Failed to load {path}: {e}") return None def merge_test_sets(sets: list[dict[str, Any]]) -> dict[str, Any]: """Merge multiple test sets, preferring more complete labels.""" merged: dict[str, dict[str, Any]] = {} for test_set in sets: queries = test_set.get('queries', {}) for query, labels in queries.items(): if query not in merged: merged[query] = labels.copy() else: # Merge labels, preferring non-empty lists existing = merged[query] for level in ['highly_relevant', 'relevant', 'somewhat_relevant', 'marginally_relevant', 'irrelevant']: existing_list = existing.get(level, []) new_list = labels.get(level, []) # Combine and deduplicate combined = list(set(existing_list + new_list)) existing[level] = combined return merged def score_test_set(test_set: dict[str, Any]) -> float: """Score test set quality (higher is better).""" queries = test_set.get('queries', {}) if not queries: return 0.0 num_queries = len(queries) total_labels = 0 queries_with_labels = 0 for q, labels in queries.items(): has_labels = any(labels.get(level, []) for level in ['highly_relevant', 'relevant', 'somewhat_relevant']) if has_labels: queries_with_labels += 1 for level in ['highly_relevant', 'relevant', 'somewhat_relevant', 'marginally_relevant', 'irrelevant']: total_labels += len(labels.get(level, [])) completeness = queries_with_labels / num_queries if num_queries > 0 else 0 avg_labels = total_labels / num_queries if num_queries > 0 else 0 # Score: completeness * size * (1 + avg_labels/10) return completeness * num_queries * (1 + avg_labels / 10) def find_best_test_sets(experiments_dir: Path, game: str) -> list[Path]: """Find best test sets for a game.""" pattern = f"test_set_*{game}*.json" test_sets = list(experiments_dir.glob(pattern)) # Score and sort scored = [] for path in test_sets: data = load_test_set(path) if data: score = score_test_set(data) scored.append((score, path, data)) # Sort by score (descending) scored.sort(key=lambda x: x[0], reverse=True) # Return top 3 return [path for _, path, _ in scored[:3]] def unify_game_test_sets(game: str, experiments_dir: Path, output_path: Path) -> dict[str, Any]: """Unify test sets for a specific game.""" print(f"\n{'='*70}") print(f"UNIFYING {game.upper()} TEST SETS") print(f"{'='*70}") # Find best test sets best_sets = find_best_test_sets(experiments_dir, game) if not best_sets: print(f"WARNING: No test sets found for {game}") return {} print(f"Found {len(best_sets)} test sets:") for path in best_sets: data = load_test_set(path) if data: queries = data.get('queries', {}) score = score_test_set(data) print(f" {path.name}: {len(queries)} queries (score: {score:.1f})") # Load and merge test_sets_data = [] for path in best_sets: data = load_test_set(path) if data: test_sets_data.append(data) if not test_sets_data: print(f"ERROR: No valid test sets to merge for {game}") return {} merged_queries = merge_test_sets(test_sets_data) # Create unified test set unified = { "version": "unified_v1", "game": game, "description": f"Unified test set for {game} (merged from {len(best_sets)} sources)", "queries": merged_queries, "num_queries": len(merged_queries), "metadata": { "sources": [path.name for path in best_sets], "merged_count": len(best_sets), } } # Save output_path.parent.mkdir(parents=True, exist_ok=True) with open(output_path, 'w') as f: json.dump(unified, f, indent=2) print(f"\nUnified test set created:") print(f" Output: {output_path}") print(f" Queries: {len(merged_queries)}") # Count labels total_labels = sum( len(labels.get(level, [])) for labels in merged_queries.values() for level in ['highly_relevant', 'relevant', 'somewhat_relevant', 'marginally_relevant', 'irrelevant'] ) print(f" Total labels: {total_labels}") print(f" Avg labels/query: {total_labels/len(merged_queries) if merged_queries else 0:.1f}") return unified def main() -> int: """Unify test sets for all games.""" experiments_dir = Path("experiments") if not experiments_dir.exists(): print(f"ERROR: {experiments_dir} does not exist") return 1 games = ["magic", "pokemon", "yugioh"] unified_paths = {} for game in games: output_path = experiments_dir / f"test_set_unified_{game}.json" unified = unify_game_test_sets(game, experiments_dir, output_path) if unified: unified_paths[game] = output_path # Summary print(f"\n{'='*70}") print("UNIFICATION SUMMARY") print(f"{'='*70}") for game, path in unified_paths.items(): if path.exists(): data = load_test_set(path) if data: queries = data.get('queries', {}) print(f"{game:10} {len(queries):>4} queries -> {path.name}") # Sync to S3 print(f"\n{'='*70}") print("SYNCING TO S3") print(f"{'='*70}") import subprocess for game, path in unified_paths.items(): if path.exists(): s3_path = f"s3://games-collections/experiments/{path.name}" print(f"Syncing {path.name}...") result = subprocess.run( ["aws", "s3", "cp", str(path), s3_path], capture_output=True, text=True ) if result.returncode == 0: print(f" Synced to {s3_path}") else: print(f" Warning: Failed: {result.stderr}") return 0 if __name__ == "__main__": sys.exit(main())