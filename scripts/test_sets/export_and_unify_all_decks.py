#!/usr/bin/env python3 # /// script # requires-python = ">=3.11" # dependencies = [] # /// """ Export and unify all deck data from canonical storage. Exports decks from all games and sources, then unifies them into: 1. Per-game files: data/decks/{game}_decks.jsonl 2. Unified file: data/processed/decks_all_unified.jsonl (with game field) """ from __future__ import annotations import argparse import json import subprocess import sys from pathlib import Path from typing import Any def build_export_tool() -> Path: """Build export-hetero tool if needed.""" export_binary = Path("bin/export-hetero") if export_binary.exists(): return export_binary print("Building export-hetero tool...") result = subprocess.run( ["go", "build", "-o", "bin/export-hetero", "src/backend/cmd/export-hetero/main.go"], cwd=Path.cwd(), capture_output=True, text=True, ) if result.returncode != 0: print(f"Error: Failed to build export-hetero: {result.stderr}") sys.exit(1) return export_binary def export_decks( canonical_dir: Path, output_file: Path, game: str, source: str, ) -> int: """Export decks from canonical directory.""" if not canonical_dir.exists(): print(f"Warning: Directory not found: {canonical_dir}") return 0 export_binary = build_export_tool() temp_output = output_file.parent / f"{output_file.name}.tmp" print(f"Exporting {game} decks from {source}...") result = subprocess.run( [str(export_binary), str(canonical_dir), str(temp_output)], capture_output=True, text=True, ) if result.returncode != 0: print(f"Error: Export failed: {result.stderr}") if temp_output.exists(): temp_output.unlink() return 0 # Count exported if temp_output.exists(): count = sum(1 for _ in open(temp_output)) temp_output.rename(output_file) print(f" Exported {count:,} {game} decks from {source}") return count return 0 def unify_decks( game_files: dict[str, list[Path]], output_file: Path, ) -> int: """Unify all deck files into a single file with game field.""" print(f"\nUnifying all decks into {output_file}...") total = 0 with open(output_file, "w") as out: for game, files in game_files.items(): for file_path in files: if not file_path.exists(): continue with open(file_path) as f: for line in f: if not line.strip(): continue deck = json.loads(line) # Add game field deck["game"] = game json.dump(deck, out) out.write("\n") total += 1 print(f" Unified {total:,} decks from all games") return total def main() -> int: """Export and unify all deck data.""" parser = argparse.ArgumentParser(description="Export and unify all deck data") parser.add_argument("--skip-export", action="store_true", help="Skip export, only unify existing files") parser.add_argument("--skip-unify", action="store_true", help="Skip unification, only export") parser.add_argument("--output-dir", type=Path, default=Path("data/decks"), help="Output directory for per-game files") parser.add_argument("--unified-file", type=Path, default=Path("data/processed/decks_all_unified.jsonl"), help="Unified output file") args = parser.parse_args() # Define canonical data sources canonical_base = Path("src/backend/data-full/games") deck_sources = { "magic": [ ("mtgtop8", canonical_base / "magic/mtgtop8/collections"), # Note: goldfish and deckbox may not have /collections subdirectory # They might be directly in the dataset directory ("goldfish", canonical_base / "magic/goldfish"), ("deckbox", canonical_base / "magic/deckbox"), ], "pokemon": [ ("limitless", canonical_base / "pokemon/limitless-web"), ], "yugioh": [ ("ygoprodeck", canonical_base / "yugioh/ygoprodeck-tournament"), ], } # Create output directory args.output_dir.mkdir(parents=True, exist_ok=True) args.unified_file.parent.mkdir(parents=True, exist_ok=True) # Export decks game_files: dict[str, list[Path]] = {} total_exported = 0 if not args.skip_export: print("=" * 70) print("EXPORTING DECKS FROM CANONICAL STORAGE") print("=" * 70) for game, sources in deck_sources.items(): game_files[game] = [] for source_name, canonical_dir in sources: output_file = args.output_dir / f"{game}_{source_name}_decks.jsonl" if output_file.exists() and not args.skip_export: # Check if we should re-export count = sum(1 for _ in open(output_file)) print(f"Warning: {output_file} exists with {count:,} decks, skipping...") game_files[game].append(output_file) else: count = export_decks(canonical_dir, output_file, game, source_name) if count > 0: game_files[game].append(output_file) total_exported += count else: # Load existing files print("Loading existing deck files...") for game in deck_sources.keys(): game_files[game] = [] for pattern in [f"{game}_*_decks.jsonl", f"decks_{game}.jsonl", f"{game}_decks.jsonl"]: for file_path in args.output_dir.glob(pattern): if file_path not in game_files[game]: game_files[game].append(file_path) # Also check processed directory processed_file = Path("data/processed") / f"decks_{game}.jsonl" if processed_file.exists() and processed_file not in game_files[game]: game_files[game].append(processed_file) # Print summary print("\n" + "=" * 70) print("EXPORT SUMMARY") print("=" * 70) for game, files in game_files.items(): total = 0 for f in files: if f.exists(): total += sum(1 for _ in open(f)) print(f"{game}: {total:,} decks from {len(files)} source(s)") # Unify decks if not args.skip_unify: print("\n" + "=" * 70) print("UNIFYING ALL DECKS") print("=" * 70) unified_count = unify_decks(game_files, args.unified_file) print("\n" + "=" * 70) print("FINAL SUMMARY") print("=" * 70) print(f"Unified file: {args.unified_file}") print(f"Total decks: {unified_count:,}") print(f"Per-game files: {args.output_dir}/") return 0 if __name__ == "__main__": sys.exit(main())