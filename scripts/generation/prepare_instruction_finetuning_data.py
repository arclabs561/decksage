#!/usr/bin/env python3 # /// script # requires-python = ">=3.11" # dependencies = [ # "pandas>=2.0.0", # "numpy<2.0.0", # ] # /// """ Prepare multi-task training data for instruction embedding fine-tuning. Creates training examples for all downstream tasks: 1. Substitution (from substitution pairs + annotations) 2. Similarity (from test sets) 3. Completion (from deck completion test data) 4. Synergy (from contextual discovery queries) 5. Upgrade/Downgrade (from contextual discovery queries) Outputs training data in format expected by train_instruction_finetune.py. """ from __future__ import annotations import argparse import json import logging from pathlib import Path from typing import Any try: import pandas as pd HAS_PANDAS = True except ImportError: HAS_PANDAS = False import sys _script_file = Path(__file__).resolve() _src_dir = _script_file.parent.parent / "src" if str(_src_dir) not in sys.path: sys.path.insert(0, str(_src_dir)) # Import paths directly to avoid pandas dependency from pathlib import Path as _Path _project_root = _script_file.parent.parent _experiments_dir = _project_root / "experiments" _graphs_dir = _project_root / "data" / "graphs" # Import annotation utils directly try: from ml.utils.annotation_utils import load_similarity_annotations, extract_substitution_pairs_from_annotations except ImportError: # Fallback if annotation_utils not available def load_similarity_annotations(path: Path) -> list[dict[str, Any]]: """Load similarity annotations from JSONL or YAML.""" if path.suffix == ".yaml": import yaml with open(path) as f: data = yaml.safe_load(f) annotations = [] for query, candidates in data.get("queries", {}).items(): for cand in candidates: annotations.append({ "card1": query, "card2": cand.get("name", ""), "similarity_score": cand.get("relevance", 0) / 4.0, "is_substitute": cand.get("is_substitute", False) or (cand.get("relevance") == 4 and cand.get("similarity_type") == "substitute"), }) return annotations else: # JSONL annotations = [] with open(path) as f: for line in f: if line.strip(): annotations.append(json.loads(line)) return annotations def extract_substitution_pairs_from_annotations(annotations: list[dict[str, Any]], min_similarity: float = 0.8) -> list[tuple[str, str]]: """Extract substitution pairs from annotations.""" pairs = [] for ann in annotations: if ann.get("is_substitute") and ann.get("similarity_score", 0) >= min_similarity: pairs.append((ann["card1"], ann["card2"])) return pairs logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s') logger = logging.getLogger(__name__) def load_substitution_pairs(path: Path) -> list[tuple[str, str]]: """Load substitution pairs from JSON file.""" if not path.exists(): return [] with open(path) as f: data = json.load(f) if isinstance(data, list): return [(str(p[0]), str(p[1])) for p in data if len(p) >= 2] elif isinstance(data, dict) and "pairs" in data: return [(str(p[0]), str(p[1])) for p in data["pairs"] if len(p) >= 2] return [] def load_test_set_queries(path: Path) -> list[tuple[str, list[str]]]: """ Load queries and relevant cards from test set. Returns: List of (query_card, relevant_cards) tuples """ if not path.exists(): return [] with open(path) as f: data = json.load(f) queries = data.get("queries", {}) examples = [] for query_card, labels in queries.items(): # Get highly relevant and relevant cards highly_relevant = labels.get("highly_relevant", []) relevant = labels.get("relevant", []) all_relevant = highly_relevant + relevant if all_relevant: examples.append((query_card, all_relevant)) return examples def create_multi_task_training_data( substitution_pairs_path: Path | None = None, test_set_path: Path | None = None, annotations_path: Path | None = None, graph_path: Path | None = None, output_path: Path | None = None, ) -> dict[str, list[tuple[str, str]]]: """ Create multi-task training data for instruction fine-tuning. Returns: Dictionary mapping task_type -> list of (query, target) pairs """ training_data: dict[str, list[tuple[str, str]]] = { "substitution": [], "similarity": [], "completion": [], "synergy": [], "upgrade": [], "downgrade": [], } # Task 1: Substitution pairs if substitution_pairs_path and substitution_pairs_path.exists(): logger.info(f"Loading substitution pairs from {substitution_pairs_path}...") pairs = load_substitution_pairs(substitution_pairs_path) training_data["substitution"].extend(pairs) logger.info(f" Loaded {len(pairs)} substitution pairs") # Task 2: Similarity from test sets if test_set_path and test_set_path.exists(): logger.info(f"Loading similarity examples from {test_set_path}...") examples = load_test_set_queries(test_set_path) for query, relevant_cards in examples: for card in relevant_cards: training_data["similarity"].append((query, card)) logger.info(f" Loaded {len(examples)} queries, {sum(len(cards) for _, cards in examples)} similarity pairs") # Task 3: Substitution from annotations if annotations_path and annotations_path.exists(): logger.info(f"Loading annotations from {annotations_path}...") try: annotations = load_similarity_annotations(annotations_path) pairs = extract_substitution_pairs_from_annotations(annotations, min_similarity=0.7) training_data["substitution"].extend(pairs) logger.info(f" Loaded {len(pairs)} substitution pairs from annotations") except Exception as e: logger.warning(f" Failed to load annotations: {e}") # Task 4: Graph edges as positive pairs (for similarity/completion) if graph_path and graph_path.exists(): logger.info(f"Loading positive pairs from graph: {graph_path}...") try: try: from ml.data.incremental_graph import IncrementalCardGraph except ImportError: logger.warning(f" Cannot import IncrementalCardGraph, skipping graph data") IncrementalCardGraph = None if IncrementalCardGraph: use_sqlite = graph_path.suffix == ".db" graph = IncrementalCardGraph(graph_path, use_sqlite=use_sqlite) # Load graph (path already provided in constructor) try: graph.load() except TypeError: # Fallback if load() requires path argument graph.load(path=graph_path) # Sample high-weight edges as positive pairs edges = graph.query_edges(min_weight=2) import random if len(edges) > 0: sampled_edges = random.sample(edges, min(10000, len(edges))) for edge in sampled_edges: # Use for similarity task training_data["similarity"].append((edge.card1, edge.card2)) training_data["similarity"].append((edge.card2, edge.card1)) # Bidirectional logger.info(f" Loaded {len(sampled_edges)} graph edges as similarity pairs") else: logger.warning(f" No edges found in graph (min_weight=2)") except Exception as e: logger.warning(f" Failed to load graph: {e}") # Remove duplicates for task_type in training_data: # Convert to set of tuples to remove duplicates unique_pairs = list(set(training_data[task_type])) training_data[task_type] = unique_pairs logger.info(f"Task '{task_type}': {len(unique_pairs)} unique pairs") # Save to output file if output_path: output_path.parent.mkdir(parents=True, exist_ok=True) with open(output_path, 'w') as f: json.dump(training_data, f, indent=2) logger.info(f" Saved training data to {output_path}") return training_data def main() -> int: """Prepare multi-task training data.""" parser = argparse.ArgumentParser(description="Prepare multi-task training data for instruction fine-tuning") parser.add_argument("--substitution-pairs", type=Path, help="Substitution pairs JSON") parser.add_argument("--test-set", type=Path, help="Test set JSON (for similarity task)") parser.add_argument("--annotations", type=Path, help="Annotations JSONL/YAML (for substitution)") parser.add_argument("--graph", type=Path, help="Incremental graph (for positive pairs)") parser.add_argument("--output", type=Path, required=True, help="Output JSON file") args = parser.parse_args() # Default paths if not provided if not args.substitution_pairs: # Try to find substitution pairs candidates = [ Path("experiments/substitution_pairs_combined.json"), Path("experiments/substitution_pairs_from_llm.json"), ] for cand in candidates: if cand.exists(): args.substitution_pairs = cand break if not args.test_set: # Use unified test set test_candidates = [ _experiments_dir / "test_set_unified_magic.json", Path("experiments/test_set_unified_magic.json"), ] for cand in test_candidates: if cand.exists(): args.test_set = cand break if not args.graph: # Try to find graph graph_candidates = [ _graphs_dir / "incremental_graph.db", _graphs_dir / "incremental_graph.json", Path("data/graphs/incremental_graph.db"), Path("data/graphs/incremental_graph.json"), ] for cand in graph_candidates: if cand.exists(): args.graph = cand break try: training_data = create_multi_task_training_data( substitution_pairs_path=args.substitution_pairs, test_set_path=args.test_set, annotations_path=args.annotations, graph_path=args.graph, output_path=args.output, ) # Print summary logger.info("\n" + "="*70) logger.info("TRAINING DATA SUMMARY") logger.info("="*70) total_pairs = sum(len(pairs) for pairs in training_data.values()) logger.info(f"Total training pairs: {total_pairs}") for task_type, pairs in training_data.items(): logger.info(f" {task_type}: {len(pairs)} pairs") logger.info("\n Training data preparation complete!") return 0 except Exception as e: logger.error(f"Error: Failed to prepare training data: {e}", exc_info=True) return 1 if __name__ == "__main__": exit(main())