#!/usr/bin/env python3 # /// script # requires-python = ">=3.11" # dependencies = [ # "pandas", # ] # /// """ Aggregate and report LLM costs across multiple sessions. Usage: python report_llm_costs.py --reports-dir experiments/cost_reports --output cost_summary.json """ from __future__ import annotations import argparse import json from collections import defaultdict from pathlib import Path try: import pandas as pd HAS_PANDAS = True except ImportError: HAS_PANDAS = False def load_reports(reports_dir: Path) -> list[dict]: """Load all cost reports from directory.""" reports = [] for report_file in reports_dir.glob("*.json"): try: with open(report_file) as f: data = json.load(f) if "summary" in data: reports.append(data) except Exception as e: print(f"Warning: Could not load {report_file}: {e}") return reports def aggregate_costs(reports: list[dict]) -> dict: """Aggregate costs across all reports.""" total = { "total_calls": 0, "total_cache_hits": 0, "total_cache_misses": 0, "total_input_tokens": 0, "total_output_tokens": 0, "total_cost_usd": 0.0, "by_model": defaultdict(lambda: { "calls": 0, "cache_hits": 0, "input_tokens": 0, "output_tokens": 0, "cost_usd": 0.0, }), "by_operation": defaultdict(lambda: { "calls": 0, "cache_hits": 0, "input_tokens": 0, "output_tokens": 0, "cost_usd": 0.0, }), "sessions": len(reports), } for report in reports: summary = report.get("summary", {}) total["total_calls"] += summary.get("total_calls", 0) total["total_cache_hits"] += summary.get("cache_hits", 0) total["total_cache_misses"] += summary.get("cache_misses", 0) total["total_input_tokens"] += summary.get("total_input_tokens", 0) total["total_output_tokens"] += summary.get("total_output_tokens", 0) total["total_cost_usd"] += summary.get("total_cost_usd", 0.0) # Aggregate by model for model, stats in summary.get("by_model", {}).items(): total["by_model"][model]["calls"] += stats.get("calls", 0) total["by_model"][model]["cache_hits"] += stats.get("cache_hits", 0) total["by_model"][model]["input_tokens"] += stats.get("input_tokens", 0) total["by_model"][model]["output_tokens"] += stats.get("output_tokens", 0) total["by_model"][model]["cost_usd"] += stats.get("cost_usd", 0.0) # Aggregate by operation for op, stats in summary.get("by_operation", {}).items(): total["by_operation"][op]["calls"] += stats.get("calls", 0) total["by_operation"][op]["cache_hits"] += stats.get("cache_hits", 0) total["by_operation"][op]["input_tokens"] += stats.get("input_tokens", 0) total["by_operation"][op]["output_tokens"] += stats.get("output_tokens", 0) total["by_operation"][op]["cost_usd"] += stats.get("cost_usd", 0.0) # Convert defaultdicts to dicts total["by_model"] = dict(total["by_model"]) total["by_operation"] = dict(total["by_operation"]) return total def print_summary(aggregated: dict): """Print formatted summary.""" print("\n" + "=" * 70) print("AGGREGATED LLM COST SUMMARY") print("=" * 70) print(f"Sessions: {aggregated['sessions']}") print(f"Total Calls: {aggregated['total_calls']:,}") if aggregated['total_calls'] > 0: hit_rate = aggregated['total_cache_hits'] / aggregated['total_calls'] * 100 print(f"Cache Hit Rate: {hit_rate:.1f}% ({aggregated['total_cache_hits']:,} hits, {aggregated['total_cache_misses']:,} misses)") print(f"Total Input Tokens: {aggregated['total_input_tokens']:,}") print(f"Total Output Tokens: {aggregated['total_output_tokens']:,}") print(f"Total Cost: ${aggregated['total_cost_usd']:.4f}") if aggregated['by_model']: print("\nBy Model:") for model, stats in sorted(aggregated['by_model'].items(), key=lambda x: x[1]['cost_usd'], reverse=True): print(f" {model}:") print(f" Calls: {stats['calls']:,} (hits: {stats['cache_hits']:,})") print(f" Tokens: {stats['input_tokens']:,} in, {stats['output_tokens']:,} out") print(f" Cost: ${stats['cost_usd']:.4f}") if aggregated['by_operation']: print("\nBy Operation:") for op, stats in sorted(aggregated['by_operation'].items(), key=lambda x: x[1]['cost_usd'], reverse=True): print(f" {op}:") print(f" Calls: {stats['calls']:,} (hits: {stats['cache_hits']:,})") print(f" Tokens: {stats['input_tokens']:,} in, {stats['output_tokens']:,} out") print(f" Cost: ${stats['cost_usd']:.4f}") print("=" * 70 + "\n") def main() -> int: """Aggregate and report LLM costs.""" parser = argparse.ArgumentParser(description="Aggregate LLM cost reports") parser.add_argument("--reports-dir", type=str, default="experiments/cost_reports", help="Directory with cost reports") parser.add_argument("--output", type=str, help="Save aggregated summary to JSON") parser.add_argument("--csv", type=str, help="Export to CSV") args = parser.parse_args() reports_dir = Path(args.reports_dir) if not reports_dir.exists(): print(f"Error: Reports directory not found: {reports_dir}") return 1 reports = load_reports(reports_dir) if not reports: print(f"Warning: No reports found in {reports_dir}") return 1 print(f" Loaded {len(reports)} cost reports") aggregated = aggregate_costs(reports) print_summary(aggregated) # Save JSON if args.output: output_path = Path(args.output) output_path.parent.mkdir(parents=True, exist_ok=True) with open(output_path, "w") as f: json.dump(aggregated, f, indent=2) print(f" Saved aggregated summary to: {output_path}") # Save CSV if args.csv and HAS_PANDAS: # Create DataFrame from records records = [] for report in reports: session = report.get("session_name", "unknown") timestamp = report.get("timestamp", "") summary = report.get("summary", {}) # Per-model records for model, stats in summary.get("by_model", {}).items(): records.append({ "session": session, "timestamp": timestamp, "model": model, "operation": "all", "calls": stats.get("calls", 0), "cache_hits": stats.get("cache_hits", 0), "input_tokens": stats.get("input_tokens", 0), "output_tokens": stats.get("output_tokens", 0), "cost_usd": stats.get("cost_usd", 0.0), }) # Per-operation records for op, stats in summary.get("by_operation", {}).items(): records.append({ "session": session, "timestamp": timestamp, "model": "all", "operation": op, "calls": stats.get("calls", 0), "cache_hits": stats.get("cache_hits", 0), "input_tokens": stats.get("input_tokens", 0), "output_tokens": stats.get("output_tokens", 0), "cost_usd": stats.get("cost_usd", 0.0), }) if records: df = pd.DataFrame(records) csv_path = Path(args.csv) csv_path.parent.mkdir(parents=True, exist_ok=True) df.to_csv(csv_path, index=False) print(f" Saved CSV to: {csv_path}") return 0 if __name__ == "__main__": import sys sys.exit(main())
