#!/usr/bin/env python3 # /// script # requires-python = ">=3.11" # dependencies = [ # "pandas>=2.0.0", # "numpy<2.0.0", # "gensim>=4.3.0", # "scipy>=1.10.0", # ] # /// """ Advanced fusion weight optimization using multiple methods. Methods: 1. Proportional (baseline) - weights proportional to signal performance 2. Grid search - exhaustive search over weight space 3. Random search - random sampling of weight space 4. Simulated annealing - iterative improvement 5. Bayesian optimization (if scipy available) - probabilistic optimization Uses PEP 723 inline dependencies. """ from __future__ import annotations import argparse import json import random from pathlib import Path from typing import Any, Callable try: import pandas as pd import numpy as np from gensim.models import KeyedVectors HAS_DEPS = True except ImportError as e: HAS_DEPS = False print(f"Missing dependencies: {e}") try: from scipy.optimize import minimize, differential_evolution HAS_SCIPY = True except ImportError: HAS_SCIPY = False def load_test_set(test_set_path: Path) -> dict[str, dict[str, Any]]: """Load test set (uses canonical implementation).""" from ml.utils.data_loading import load_test_set as canonical_load data = canonical_load(path=test_set_path) if "queries" in data: return data["queries"] return data def load_graph_for_jaccard(pairs_csv: Path | None = None, graph_db: Path | None = None, game: str | None = None) -> dict[str, set[str]]: """Load graph adjacency (uses shared implementation).""" from ml.utils.shared_operations import load_graph_for_jaccard as shared_load return shared_load(pairs_csv=pairs_csv, graph_db=graph_db, game=game) def evaluate_weights( weights: dict[str, float], wv: KeyedVectors, adj: dict[str, set[str]], test_set: dict[str, dict[str, Any]], top_k: int = 10, ) -> float: """Evaluate fusion weights and return P@10 score.""" # Simple fusion evaluation correct = 0 total = 0 relevance_weights = { "highly_relevant": 1.0, "relevant": 0.75, "somewhat_relevant": 0.5, "marginally_relevant": 0.25, } def jaccard_similarity(set1: set[str], set2: set[str]) -> float: intersection = len(set1 & set2) union = len(set1 | set2) return intersection / union if union > 0 else 0.0 for query, labels in test_set.items(): all_relevant = set() for level in ["highly_relevant", "relevant", "somewhat_relevant", "marginally_relevant"]: all_relevant.update(labels.get(level, [])) if not all_relevant: continue # Get embedding scores embed_scores = {} if query in wv and weights.get("embed", 0) > 0: try: similar = wv.most_similar(query, topn=top_k * 2) for card, sim in similar: embed_scores[card] = float(sim) except KeyError: pass # Get Jaccard scores jaccard_scores = {} if query in adj and weights.get("jaccard", 0) > 0: query_neighbors = adj[query] for candidate in adj.keys(): if candidate == query: continue candidate_neighbors = adj[candidate] sim = jaccard_similarity(query_neighbors, candidate_neighbors) jaccard_scores[candidate] = sim # Combine all_candidates = set(embed_scores.keys()) | set(jaccard_scores.keys()) combined_scores = {} for candidate in all_candidates: score = 0.0 if candidate in embed_scores: score += weights.get("embed", 0) * embed_scores[candidate] if candidate in jaccard_scores: score += weights.get("jaccard", 0) * jaccard_scores[candidate] combined_scores[candidate] = score candidates = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)[:top_k] candidate_cards = [card for card, _ in candidates] score = 0.0 for card in candidate_cards[:top_k]: for level, weight in relevance_weights.items(): if card in labels.get(level, []): score += weight break precision_at_k = score / top_k if precision_at_k > 0: correct += 1 total += 1 return correct / total if total > 0 else 0.0 def proportional_optimization( signal_performance: dict[str, float], ) -> dict[str, float]: """Proportional weights based on signal performance.""" total = sum(signal_performance.values()) if total == 0: return {"embed": 0.5, "jaccard": 0.5, "functional": 0.0} weights = {k: v / total for k, v in signal_performance.items()} return { "embed": weights.get("embedding", 0.0), "jaccard": weights.get("jaccard", 0.0), "functional": weights.get("functional", 0.0), } def grid_search_optimization( wv: KeyedVectors, adj: dict[str, set[str]], test_set: dict[str, dict[str, Any]], step: float = 0.1, top_k: int = 10, max_queries: int = 20, # Limit for speed ) -> tuple[dict[str, float], float]: """Grid search over weight space (optimized for speed).""" best_weights = {"embed": 0.5, "jaccard": 0.5, "functional": 0.0} best_score = 0.0 # Limit test set size for speed test_items = list(test_set.items())[:max_queries] limited_test_set = dict(test_items) total_combos = 0 for embed_w in np.arange(0.0, 1.01, step): for jaccard_w in np.arange(0.0, 1.01 - embed_w, step): func_w = 1.0 - embed_w - jaccard_w if func_w < 0: continue total_combos += 1 weights = {"embed": embed_w, "jaccard": jaccard_w, "functional": func_w} score = evaluate_weights(weights, wv, adj, limited_test_set, top_k) if score > best_score: best_score = score best_weights = weights print(f" Evaluated {total_combos} weight combinations") return best_weights, best_score def random_search_optimization( wv: KeyedVectors, adj: dict[str, set[str]], test_set: dict[str, dict[str, Any]], n_iterations: int = 50, # Reduced default top_k: int = 10, max_queries: int = 20, # Limit for speed ) -> tuple[dict[str, float], float]: """Random search over weight space (optimized for speed).""" best_weights = {"embed": 0.5, "jaccard": 0.5, "functional": 0.0} best_score = 0.0 # Limit test set size for speed test_items = list(test_set.items())[:max_queries] limited_test_set = dict(test_items) for i in range(n_iterations): # Sample from simplex x = np.random.random(2) x = x / x.sum() embed_w, jaccard_w = x[0], x[1] func_w = 1.0 - embed_w - jaccard_w weights = {"embed": embed_w, "jaccard": jaccard_w, "functional": func_w} score = evaluate_weights(weights, wv, adj, limited_test_set, top_k) if score > best_score: best_score = score best_weights = weights if (i + 1) % 10 == 0: print(f" Iteration {i+1}/{n_iterations}, best P@10: {best_score:.4f}") return best_weights, best_score def simulated_annealing_optimization( wv: KeyedVectors, adj: dict[str, set[str]], test_set: dict[str, dict[str, Any]], initial_weights: dict[str, float], n_iterations: int = 50, # Reduced default initial_temp: float = 1.0, top_k: int = 10, max_queries: int = 20, # Limit for speed ) -> tuple[dict[str, float], float]: """Simulated annealing optimization (optimized for speed).""" # Limit test set size for speed test_items = list(test_set.items())[:max_queries] limited_test_set = dict(test_items) current_weights = initial_weights.copy() current_score = evaluate_weights(current_weights, wv, adj, limited_test_set, top_k) best_weights = current_weights.copy() best_score = current_score temp = initial_temp for i in range(n_iterations): # Generate neighbor neighbor = current_weights.copy() delta = np.random.normal(0, 0.1, 2) neighbor["embed"] = max(0.0, min(1.0, neighbor["embed"] + delta[0])) neighbor["jaccard"] = max(0.0, min(1.0, neighbor["jaccard"] + delta[1])) neighbor["functional"] = 1.0 - neighbor["embed"] - neighbor["jaccard"] if neighbor["functional"] < 0: continue neighbor_score = evaluate_weights(neighbor, wv, adj, limited_test_set, top_k) # Accept or reject if neighbor_score > current_score or random.random() < np.exp((neighbor_score - current_score) / temp): current_weights = neighbor current_score = neighbor_score if current_score > best_score: best_score = current_score best_weights = current_weights.copy() # Cool down temp *= 0.95 if (i + 1) % 10 == 0: print(f" Iteration {i+1}/{n_iterations}, best P@10: {best_score:.4f}, temp: {temp:.3f}") return best_weights, best_score def scipy_optimization( wv: KeyedVectors, adj: dict[str, set[str]], test_set: dict[str, dict[str, Any]], top_k: int = 10, ) -> tuple[dict[str, float], float]: """Scipy-based optimization (differential evolution).""" if not HAS_SCIPY: return {"embed": 0.5, "jaccard": 0.5, "functional": 0.0}, 0.0 def objective(x: np.ndarray) -> float: """Minimize negative P@10.""" weights = {"embed": x[0], "jaccard": x[1], "functional": 1.0 - x[0] - x[1]} if weights["functional"] < 0: return 1.0 # Penalty score = evaluate_weights(weights, wv, adj, test_set, top_k) return -score # Minimize negative = maximize # Bounds: embed and jaccard in [0, 1], sum <= 1 bounds = [(0.0, 1.0), (0.0, 1.0)] # Constraint: embed + jaccard <= 1 def constraint(x: np.ndarray) -> float: return 1.0 - x[0] - x[1] from scipy.optimize import NonlinearConstraint constraints = NonlinearConstraint(constraint, 0.0, 1.0) result = differential_evolution( objective, bounds, constraints=constraints, seed=42, maxiter=50, ) weights = { "embed": result.x[0], "jaccard": result.x[1], "functional": 1.0 - result.x[0] - result.x[1], } score = -result.fun return weights, score def main() -> int: """Run advanced weight optimization.""" parser = argparse.ArgumentParser(description="Advanced fusion weight optimization") parser.add_argument( "--test-set", type=str, default="experiments/test_set_unified_magic.json", help="Test set path", ) parser.add_argument( "--pairs-csv", type=str, default="data/processed/pairs_large.csv", help="Pairs CSV", ) parser.add_argument( "--embeddings", type=str, default="data/embeddings/node2vec_default.wv", help="Embeddings file", ) parser.add_argument( "--signal-performance", type=str, default="experiments/individual_signal_performance.json", help="Signal performance JSON", ) parser.add_argument( "--output", type=str, default="experiments/advanced_optimization_results.json", help="Output JSON", ) parser.add_argument( "--methods", type=str, nargs="+", default=["proportional", "grid", "random", "annealing"], choices=["proportional", "grid", "random", "annealing", "scipy"], help="Optimization methods to use", ) parser.add_argument( "--grid-step", type=float, default=0.1, help="Grid search step size", ) parser.add_argument( "--random-iterations", type=int, default=100, help="Random search iterations", ) parser.add_argument( "--annealing-iterations", type=int, default=100, help="Simulated annealing iterations", ) args = parser.parse_args() if not HAS_DEPS: print("Error: Missing dependencies") return 1 print("=" * 70) print("Advanced Fusion Weight Optimization") print("=" * 70) print() # Load data test_set_path = Path(args.test_set) if not test_set_path.exists(): print(f"Error: Test set not found: {test_set_path}") return 1 test_set = load_test_set(test_set_path) print(f" Loaded test set: {len(test_set)} queries") embed_path = Path(args.embeddings) if not embed_path.exists(): print(f"Error: Embeddings not found: {embed_path}") return 1 wv = KeyedVectors.load(str(embed_path)) print(f" Loaded embeddings: {len(wv):,} cards") pairs_csv = Path(args.pairs_csv) if not pairs_csv.exists(): print(f"Error: Pairs CSV not found: {pairs_csv}") return 1 adj = load_graph_for_jaccard(pairs_csv) print() # Load signal performance signal_perf_path = Path(args.signal_performance) signal_performance = {} if signal_perf_path.exists(): with open(signal_perf_path) as f: data = json.load(f) for signal, metrics in data.get("results", {}).items(): if "error" not in metrics: signal_performance[signal] = metrics.get("p@10", 0.0) results = {} # Run optimization methods if "proportional" in args.methods: print("1. Proportional Optimization...") weights = proportional_optimization(signal_performance) score = evaluate_weights(weights, wv, adj, test_set) results["proportional"] = {"weights": weights, "p@10": score} print(f" Weights: embed={weights['embed']:.4f}, jaccard={weights['jaccard']:.4f}") print(f" P@10: {score:.4f}") print() if "grid" in args.methods: print("2. Grid Search Optimization...") weights, score = grid_search_optimization(wv, adj, test_set, step=args.grid_step) results["grid_search"] = {"weights": weights, "p@10": score} print(f" Weights: embed={weights['embed']:.4f}, jaccard={weights['jaccard']:.4f}") print(f" P@10: {score:.4f}") print() if "random" in args.methods: print("3. Random Search Optimization...") weights, score = random_search_optimization(wv, adj, test_set, n_iterations=args.random_iterations) results["random_search"] = {"weights": weights, "p@10": score} print(f" Weights: embed={weights['embed']:.4f}, jaccard={weights['jaccard']:.4f}") print(f" P@10: {score:.4f}") print() if "annealing" in args.methods: print("4. Simulated Annealing Optimization...") initial = proportional_optimization(signal_performance) weights, score = simulated_annealing_optimization( wv, adj, test_set, initial, n_iterations=args.annealing_iterations ) results["simulated_annealing"] = {"weights": weights, "p@10": score} print(f" Weights: embed={weights['embed']:.4f}, jaccard={weights['jaccard']:.4f}") print(f" P@10: {score:.4f}") print() if "scipy" in args.methods: if HAS_SCIPY: print("5. Scipy Differential Evolution Optimization...") weights, score = scipy_optimization(wv, adj, test_set) results["scipy_optimization"] = {"weights": weights, "p@10": score} print(f" Weights: embed={weights['embed']:.4f}, jaccard={weights['jaccard']:.4f}") print(f" P@10: {score:.4f}") print() else: print("5. Scipy Optimization... (skipped - scipy not available)") print() # Summary print("=" * 70) print("Optimization Results Summary") print("=" * 70) print() sorted_results = sorted( results.items(), key=lambda x: x[1].get("p@10", 0.0), reverse=True, ) print(f"{'Method':<25} {'P@10':<10} {'Embed':<10} {'Jaccard':<10}") print("-" * 55) for method, data in sorted_results: weights = data.get("weights", {}) print( f"{method:<25} {data.get('p@10', 0.0):<10.4f} " f"{weights.get('embed', 0.0):<10.4f} {weights.get('jaccard', 0.0):<10.4f}" ) # Best method if sorted_results: best_method, best_data = sorted_results[0] print() print(f"ðŸ† Best method: {best_method}") print(f" P@10: {best_data.get('p@10', 0.0):.4f}") print(f" Weights: {best_data.get('weights', {})}") # Save results output_path = Path(args.output) output_path.parent.mkdir(parents=True, exist_ok=True) with open(output_path, "w") as f: json.dump({ "test_set": str(test_set_path), "signal_performance": signal_performance, "results": results, "best_method": best_method if sorted_results else None, "best_weights": best_data.get("weights", {}) if sorted_results else None, "best_p@10": best_data.get("p@10", 0.0) if sorted_results else None, }, f, indent=2) print() print(f" Results saved to {output_path}") return 0 if __name__ == "__main__": import sys sys.exit(main())