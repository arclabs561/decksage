#!/usr/bin/env python3 # /// script # requires-python = ">=3.11" # dependencies = [ # "pandas>=2.0.0", # "numpy<2.0.0", # "gensim>=4.3.0", # "torch>=2.0.0", # "torch-geometric>=2.0.0", # ] # /// """ Train embeddings using heterogeneous graph approach for substitution. Based on research: - Heterogeneous graphs with different edge types (co-view vs co-purchase) help separate substitutes - Multi-task learning combining supervised substitute labels with unsupervised graph structure - Different relationship types should have different importance weights Strategy: 1. Create heterogeneous graph with edge types: - co_occurrence: Standard co-occurrence edges - substitution: Known substitution pairs (high weight) - complement: Known complement pairs (low weight, for contrast) 2. Use GraphSAGE or GAT with edge type awareness 3. Multi-task loss: triplet loss for substitutes + graph structure preservation Research References: - Multi-task learning on heterogeneous graphs: https://www.mlgworkshop.org/2023/papers/MLG__KDD_2023_paper_6.pdf - Heterogeneous Graph Attention Networks: https://arxiv.org/abs/1903.07293 - Semantic and Relation-Aware neural networks: https://pmc.ncbi.nlm.nih.gov/articles/PMC11995132/ - Substitute Products Embedding Model: https://www.ijcai.org/proceedings/2019/0598.pdf - Complementary recommendation: https://arxiv.org/html/2403.16135v1 - Heterogeneous Hypergraph Embedding: https://arxiv.org/abs/2407.03665 - Metapath2vec for heterogeneous networks: https://ericdongyx.github.io/papers/KDD17-dong-chawla-swami-metapath2vec.pdf """ from __future__ import annotations import argparse import json import logging from pathlib import Path from typing import Any try: import pandas as pd import numpy as np import torch import torch.nn as nn import torch.nn.functional as F from torch_geometric.data import HeteroData from torch_geometric.nn import HeteroConv, SAGEConv, to_hetero from gensim.models import KeyedVectors HAS_DEPS = True except ImportError: HAS_DEPS = False import sys script_dir = Path(__file__).parent src_dir = script_dir.parent.parent if str(src_dir) not in sys.path: sys.path.insert(0, str(src_dir)) logging.basicConfig(level=logging.INFO) logger = logging.getLogger(__name__) def create_heterogeneous_graph( pairs_csv: Path, substitution_path: Path, cooccurrence_weight: float = 1.0, substitution_weight: float = 10.0, ) -> tuple[HeteroData, dict[str, int]]: """Create heterogeneous graph with different edge types.""" logger.info("Creating heterogeneous graph...") # Load base co-occurrence graph df = pd.read_csv(pairs_csv, nrows=50000) all_cards = sorted(set(df["NAME_1"].unique()) | set(df["NAME_2"].unique())) card_to_idx = {card: i for i, card in enumerate(all_cards)} # Initialize edge lists for different types cooccurrence_edges = [] substitution_edges = [] # Add co-occurrence edges for _, row in df.iterrows(): card1 = str(row["NAME_1"]) card2 = str(row["NAME_2"]) if card1 in card_to_idx and card2 in card_to_idx: idx1 = card_to_idx[card1] idx2 = card_to_idx[card2] weight = float(row.get("COUNT", 1.0)) * cooccurrence_weight cooccurrence_edges.append((idx1, idx2, weight)) logger.info(f" Co-occurrence edges: {len(cooccurrence_edges)}") # Add substitution edges if substitution_path.exists(): with open(substitution_path) as f: sub_data = json.load(f) sub_pairs = [] if isinstance(sub_data, list): for item in sub_data: if isinstance(item, list) and len(item) >= 2: sub_pairs.append((str(item[0]), str(item[1]))) elif isinstance(sub_data, dict): pairs_list = sub_data.get("pairs", []) for item in pairs_list: if isinstance(item, list) and len(item) >= 2: sub_pairs.append((str(item[0]), str(item[1]))) for query, target in sub_pairs: if query in card_to_idx and target in card_to_idx: idx1 = card_to_idx[query] idx2 = card_to_idx[target] substitution_edges.append((idx1, idx2, substitution_weight)) # Also add reverse substitution_edges.append((idx2, idx1, substitution_weight)) logger.info(f" Substitution edges: {len(substitution_edges)}") # Create HeteroData data = HeteroData() # Node features (can be one-hot or learned) num_nodes = len(all_cards) data['card'].x = torch.eye(num_nodes) # Identity matrix for now # Edge indices and attributes if cooccurrence_edges: cooc_src = torch.tensor([e[0] for e in cooccurrence_edges], dtype=torch.long) cooc_dst = torch.tensor([e[1] for e in cooccurrence_edges], dtype=torch.long) cooc_attr = torch.tensor([e[2] for e in cooccurrence_edges], dtype=torch.float) data['card', 'cooccurs_with', 'card'].edge_index = torch.stack([cooc_src, cooc_dst]) data['card', 'cooccurs_with', 'card'].edge_attr = cooc_attr if substitution_edges: sub_src = torch.tensor([e[0] for e in substitution_edges], dtype=torch.long) sub_dst = torch.tensor([e[1] for e in substitution_edges], dtype=torch.long) sub_attr = torch.tensor([e[2] for e in substitution_edges], dtype=torch.float) data['card', 'substitutes', 'card'].edge_index = torch.stack([sub_src, sub_dst]) data['card', 'substitutes', 'card'].edge_attr = sub_attr return data, card_to_idx class HeteroGNN(nn.Module): """Heterogeneous GNN for card embeddings.""" def __init__(self, num_nodes: int, hidden_dim: int = 128, out_dim: int = 128): super().__init__() self.num_nodes = num_nodes self.hidden_dim = hidden_dim self.out_dim = out_dim # Create heterogeneous convolution layers self.conv1 = HeteroConv({ ('card', 'cooccurs_with', 'card'): SAGEConv(-1, hidden_dim), ('card', 'substitutes', 'card'): SAGEConv(-1, hidden_dim), }, aggr='sum') self.conv2 = HeteroConv({ ('card', 'cooccurs_with', 'card'): SAGEConv(hidden_dim, out_dim), ('card', 'substitutes', 'card'): SAGEConv(hidden_dim, out_dim), }, aggr='sum') def forward(self, x_dict, edge_index_dict, edge_attr_dict): """Forward pass.""" # First layer x_dict = self.conv1(x_dict, edge_index_dict) x_dict = {key: F.relu(x) for key, x in x_dict.items()} # Second layer x_dict = self.conv2(x_dict, edge_index_dict) return x_dict def train_heterogeneous_embeddings( pairs_csv: Path, substitution_path: Path, output_path: Path, dimensions: int = 128, epochs: int = 50, learning_rate: float = 0.001, ) -> KeyedVectors: """Train embeddings using heterogeneous graph approach.""" if not HAS_DEPS: logger.error("Missing dependencies") return None logger.info("=" * 70) logger.info("TRAINING HETEROGENEOUS GRAPH EMBEDDINGS") logger.info("=" * 70) logger.info("") # Create heterogeneous graph data, card_to_idx = create_heterogeneous_graph( pairs_csv, substitution_path, cooccurrence_weight=1.0, substitution_weight=10.0, ) num_nodes = len(card_to_idx) logger.info(f"Graph: {num_nodes} nodes") # Create model model = HeteroGNN(num_nodes, hidden_dim=dimensions, out_dim=dimensions) optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) logger.info("Training...") logger.info(f" Epochs: {epochs}, Dimensions: {dimensions}") logger.info("") for epoch in range(epochs): model.train() optimizer.zero_grad() # Forward pass x_dict = {'card': data['card'].x} edge_index_dict = { ('card', 'cooccurs_with', 'card'): data['card', 'cooccurs_with', 'card'].edge_index, ('card', 'substitutes', 'card'): data['card', 'substitutes', 'card'].edge_index, } edge_attr_dict = { ('card', 'cooccurs_with', 'card'): data['card', 'cooccurs_with', 'card'].edge_attr, ('card', 'substitutes', 'card'): data['card', 'substitutes', 'card'].edge_attr, } out_dict = model(x_dict, edge_index_dict, edge_attr_dict) # Extract embeddings embeddings = out_dict['card'] # Link prediction loss on substitution edges sub_edge_index = data['card', 'substitutes', 'card'].edge_index if sub_edge_index.size(1) > 0: src, dst = sub_edge_index[0], sub_edge_index[1] pos_scores = (embeddings[src] * embeddings[dst]).sum(dim=1) # Negative sampling num_neg = src.size(0) neg_src = torch.randint(0, num_nodes, (num_neg,)) neg_dst = torch.randint(0, num_nodes, (num_neg,)) neg_scores = (embeddings[neg_src] * embeddings[neg_dst]).sum(dim=1) # Binary cross-entropy loss pos_loss = -torch.log(torch.sigmoid(pos_scores) + 1e-15).mean() neg_loss = -torch.log(1 - torch.sigmoid(neg_scores) + 1e-15).mean() loss = pos_loss + neg_loss else: loss = torch.tensor(0.0) loss.backward() optimizer.step() if (epoch + 1) % 10 == 0: logger.info(f"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}") # Extract final embeddings model.eval() with torch.no_grad(): x_dict = {'card': data['card'].x} edge_index_dict = { ('card', 'cooccurs_with', 'card'): data['card', 'cooccurs_with', 'card'].edge_index, ('card', 'substitutes', 'card'): data['card', 'substitutes', 'card'].edge_index, } edge_attr_dict = { ('card', 'cooccurs_with', 'card'): data['card', 'cooccurs_with', 'card'].edge_attr, ('card', 'substitutes', 'card'): data['card', 'substitutes', 'card'].edge_attr, } out_dict = model(x_dict, edge_index_dict, edge_attr_dict) final_embeddings = out_dict['card'].cpu().numpy() # Convert to KeyedVectors logger.info("Converting to KeyedVectors...") from gensim.models import Word2Vec model_w2v = Word2Vec(vector_size=dimensions, min_count=1) idx_to_card = {i: card for card, i in card_to_idx.items()} model_w2v.wv.key_to_index = {idx_to_card[i]: i for i in range(num_nodes)} model_w2v.wv.index_to_key = [idx_to_card[i] for i in range(num_nodes)] model_w2v.wv.vectors = final_embeddings # Save model_w2v.wv.save(str(output_path)) logger.info(f" Saved embeddings to {output_path}") return model_w2v.wv def main() -> int: parser = argparse.ArgumentParser(description="Train heterogeneous graph embeddings for substitution") parser.add_argument("--input", type=Path, required=True, help="Input pairs CSV") parser.add_argument("--substitution", type=Path, required=True, help="Substitution test pairs JSON") parser.add_argument("--output", type=Path, required=True, help="Output embedding file") parser.add_argument("--dimensions", type=int, default=128, help="Embedding dimensions") parser.add_argument("--epochs", type=int, default=50, help="Training epochs") parser.add_argument("--learning-rate", type=float, default=0.001, help="Learning rate") args = parser.parse_args() if not HAS_DEPS: logger.error("Missing dependencies") return 1 train_heterogeneous_embeddings( pairs_csv=args.input, substitution_path=args.substitution, output_path=args.output, dimensions=args.dimensions, epochs=args.epochs, learning_rate=args.learning_rate, ) return 0 if __name__ == "__main__": import sys sys.exit(main())
