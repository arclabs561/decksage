#!/usr/bin/env python3 # /// script # requires-python = ">=3.11" # dependencies = [ # "pandas>=2.0.0", # "numpy<2.0.0", # ] # /// """ Integrate Functional Tags into Training Pipeline. Adds functional similarity edges based on shared functional tags. Cards with similar functional roles get higher edge weights. """ from __future__ import annotations import argparse import json import logging from collections import defaultdict from pathlib import Path from typing import Any try: from ..utils.logging_config import setup_script_logging, log_exception logger = setup_script_logging() except ImportError: logging.basicConfig(level=logging.INFO) logger = logging.getLogger(__name__) def log_exception(logger, message, exc, level="error", include_context=True): getattr(logger, level, logger.error)(f"{message}: {exc}", exc_info=True) try: import pandas as pd import numpy as np HAS_DEPS = True except ImportError as e: HAS_DEPS = False print(f"Missing dependencies: {e}") logging.basicConfig(level=logging.INFO) logger = logging.getLogger(__name__) def load_functional_tags(attrs_csv: Path) -> dict[str, set[str]]: """Load functional tags for each card.""" if not attrs_csv.exists(): logger.warning(f"Card attributes file not found: {attrs_csv}") return {} df = pd.read_csv(attrs_csv) tags = {} # Check for functional tag columns tag_columns = [col for col in df.columns if 'tag' in col.lower() or 'functional' in col.lower()] if not tag_columns: logger.warning("No functional tag columns found - will use type/keywords as fallback") # Use type and keywords as functional tags for _, row in df.iterrows(): name = row.get("name", "") if not name or pd.isna(name): continue card_tags = set() # Add type as a tag card_type = row.get("type", "") if pd.notna(card_type) and card_type: # Extract main type (e.g., "Creature — Human Wizard" -> "Creature") main_type = str(card_type).split("—")[0].strip() if main_type: card_tags.add(main_type.lower().replace(" ", "_")) # Add keywords keywords = row.get("keywords", "") if pd.notna(keywords) and keywords: keyword_list = str(keywords).split(",") for kw in keyword_list: kw_clean = kw.strip().lower().replace(" ", "_") if kw_clean: card_tags.add(kw_clean) if card_tags: tags[name] = card_tags logger.info(f"Created functional tags from type/keywords for {len(tags)} cards") return tags for _, row in df.iterrows(): name = row.get("name", "") if not name: continue card_tags = set() for col in tag_columns: value = row.get(col) if pd.notna(value) and value: # Could be boolean, string, or comma-separated if isinstance(value, bool) and value: card_tags.add(col.replace("_tag", "").replace("is_", "")) elif isinstance(value, str): if value.lower() in ["true", "1", "yes"]: card_tags.add(col.replace("_tag", "").replace("is_", "")) elif "," in value: card_tags.update([t.strip() for t in value.split(",")]) if card_tags: tags[name] = card_tags logger.info(f"Loaded functional tags for {len(tags)} cards") logger.info(f" Total unique tags: {len(set().union(*tags.values())) if tags else 0}") return tags def compute_functional_similarity(tags1: set[str], tags2: set[str]) -> float: """Compute Jaccard similarity of functional tags.""" if not tags1 or not tags2: return 0.0 intersection = len(tags1 & tags2) union = len(tags1 | tags2) return intersection / union if union > 0 else 0.0 def create_functional_edges( card_tags: dict[str, set[str]], threshold: float = 0.3, max_edges_per_card: int = 20, ) -> list[tuple[str, str, float]]: """ Create edges based on functional tag similarity. Args: card_tags: Card -> tags mapping threshold: Minimum similarity threshold max_edges_per_card: Maximum edges per card (top-k) Returns: List of (card1, card2, similarity) tuples """ edges = [] card_names = list(card_tags.keys()) logger.info(f"Computing functional similarity for {len(card_names)} cards...") for i, card1 in enumerate(card_names): if i % 100 == 0: logger.info(f" Processing {i}/{len(card_names)}...") tags1 = card_tags[card1] if not tags1: continue similarities = [] for card2 in card_names[i+1:]: tags2 = card_tags[card2] if not tags2: continue sim = compute_functional_similarity(tags1, tags2) if sim >= threshold: similarities.append((card2, sim)) # Take top-k similarities.sort(key=lambda x: x[1], reverse=True) for card2, sim in similarities[:max_edges_per_card]: edges.append((card1, card2, sim)) logger.info(f"Created {len(edges)} functional similarity edges") return edges def merge_functional_edges_into_pairs( pairs_csv: Path, functional_edges: list[tuple[str, str, float]], output_csv: Path, functional_weight: float = 3.0, ) -> None: """ Merge functional similarity edges into pairs CSV. Enhances existing edges or adds new functional similarity edges. """ if not HAS_DEPS: raise ImportError("pandas required") logger.info(f"Loading pairs from {pairs_csv}...") pairs_df = pd.read_csv(pairs_csv) logger.info(f" Loaded {len(pairs_df)} existing pairs") # Create functional edges DataFrame func_df = pd.DataFrame(functional_edges, columns=["NAME_1", "NAME_2", "FUNCTIONAL_SIMILARITY"]) # Normalize card names (sorted) func_df["PAIR_KEY"] = func_df.apply( lambda row: tuple(sorted([row["NAME_1"], row["NAME_2"]])), axis=1 ) pairs_df["PAIR_KEY"] = pairs_df.apply( lambda row: tuple(sorted([row["NAME_1"], row["NAME_2"]])), axis=1 ) # Merge merged = pairs_df.merge( func_df[["PAIR_KEY", "FUNCTIONAL_SIMILARITY"]], on="PAIR_KEY", how="left" ) # Add new functional-only pairs existing_keys = set(merged["PAIR_KEY"]) new_pairs = [] for _, row in func_df.iterrows(): if row["PAIR_KEY"] not in existing_keys: new_pairs.append({ "NAME_1": row["NAME_1"], "NAME_2": row["NAME_2"], "COUNT_SET": 0, "COUNT_MULTISET": 0, "FUNCTIONAL_SIMILARITY": row["FUNCTIONAL_SIMILARITY"], "PAIR_KEY": row["PAIR_KEY"], }) if new_pairs: new_df = pd.DataFrame(new_pairs) merged = pd.concat([merged, new_df], ignore_index=True) logger.info(f" Added {len(new_pairs)} new functional similarity pairs") # Drop pair key column merged = merged.drop(columns=["PAIR_KEY"]) # Save merged.to_csv(output_csv, index=False) logger.info(f" Saved enhanced pairs to {output_csv}") logger.info(f" Total pairs: {len(merged)}") logger.info(f" Pairs with functional similarity: {merged['FUNCTIONAL_SIMILARITY'].notna().sum()}") def main() -> int: """Integrate functional tags into training.""" parser = argparse.ArgumentParser(description="Integrate functional tag similarity") parser.add_argument("--card-attrs", type=Path, required=True, help="Card attributes CSV with functional tags") parser.add_argument("--pairs", type=Path, help="Existing pairs CSV to enhance") parser.add_argument("--output", type=Path, required=True, help="Output CSV") parser.add_argument("--threshold", type=float, default=0.3, help="Similarity threshold") parser.add_argument("--max-edges", type=int, default=20, help="Max edges per card") parser.add_argument("--functional-weight", type=float, default=3.0, help="Weight for functional edges") args = parser.parse_args() if not HAS_DEPS: print("Error: Missing dependencies") return 1 try: # Load functional tags card_tags = load_functional_tags(args.card_attrs) if not card_tags: logger.error("No functional tags loaded") return 1 # Create functional similarity edges functional_edges = create_functional_edges( card_tags, threshold=args.threshold, max_edges_per_card=args.max_edges, ) # Merge into pairs if provided if args.pairs and args.pairs.exists(): merge_functional_edges_into_pairs( args.pairs, functional_edges, args.output, functional_weight=args.functional_weight, ) else: # Just save edges edges_df = pd.DataFrame(functional_edges, columns=["card1", "card2", "similarity"]) edges_df.to_csv(args.output, index=False) logger.info(f" Saved {len(functional_edges)} functional similarity edges to {args.output}") return 0 except Exception as e: log_exception(logger, "Integration failed", e, include_context=True) return 1 if __name__ == "__main__": exit(main())