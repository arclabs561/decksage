#!/usr/bin/env python3 # /// script # requires-python = ">=3.11" # dependencies = [ # "pandas>=2.0.0", # "numpy<2.0.0", # "gensim>=4.3.0", # ] # /// """ Improved downstream task evaluation using fusion. Uses embedding + Jaccard fusion for better performance. """ from __future__ import annotations import argparse import json from pathlib import Path from typing import Any try: import pandas as pd import numpy as np from gensim.models import KeyedVectors HAS_DEPS = True except ImportError: HAS_DEPS = False # Fix import path import sys script_dir = Path(__file__).parent src_dir = script_dir.parent.parent if str(src_dir) not in sys.path: sys.path.insert(0, str(src_dir)) try: from ml.similarity.fusion import WeightedLateFusion, FusionWeights from ml.deck_building.deck_completion import ( suggest_additions, suggest_replacements, ) from ml.deck_building.contextual_discovery import ContextualCardDiscovery HAS_DOWNSTREAM = True except ImportError: HAS_DOWNSTREAM = False # Try to load functional tagger (for Magic) try: from ml.enrichment.card_functional_tagger import FunctionalTagger _HAS_TAGGER = True except ImportError: _HAS_TAGGER = False def load_jaccard_graph(pairs_csv: Path | None = None, graph_db: Path | None = None, game: str | None = None) -> dict[str, set[str]]: """Load Jaccard graph (uses shared implementation).""" from ml.utils.shared_operations import load_jaccard_graph as shared_load return shared_load(pairs_csv=pairs_csv, graph_db=graph_db, game=game, max_rows=100000) def evaluate_with_fusion( embedding: KeyedVectors, pairs_csv: Path, test_data: dict[str, Any], game: str, task: str, ) -> dict[str, Any]: """Evaluate downstream task using fusion (embedding + Jaccard).""" if not HAS_DOWNSTREAM: return {"error": "Downstream modules not available"} # Load Jaccard graph print(" Loading Jaccard graph...") adj = load_jaccard_graph(pairs_csv) print(f" Loaded {len(adj)} cards in Jaccard graph") # Create fusion with functional tags and Oracle text if available tagger = None if _HAS_TAGGER and game == "magic": try: from ml.enrichment.card_functional_tagger import FunctionalTagger tagger = FunctionalTagger() print(" Functional tagger loaded") except Exception: pass # Try to load Oracle text embedder text_embedder = None try: from ml.similarity.text_embeddings import get_text_embedder text_embedder = get_text_embedder() print(" Oracle text embedder loaded") except Exception as e: print(f" Warning: Could not load text embedder: {e}") # Load card data for text embeddings card_data = None from ml.utils.paths import PATHS card_attrs_path = PATHS.data / "processed" / "card_attributes_enriched.csv" if card_attrs_path.exists() and text_embedder: try: import pandas as pd df = pd.read_csv(card_attrs_path, nrows=50000) card_data = {} for _, row in df.iterrows(): name = str(row["name"]) card_data[name] = { "name": name, "oracle_text": str(row.get("oracle_text", "")), "type_line": str(row.get("type", "")), # Use type_line for CardTextEmbedder "type": str(row.get("type", "")), "mana_cost": str(row.get("mana_cost", "")), } print(f" Loaded {len(card_data)} card records") except Exception as e: print(f" Warning: Could not load card data: {e}") # Use functional tags and text embeddings if available if tagger and text_embedder: weights = FusionWeights(embed=0.25, jaccard=0.35, functional=0.20, text_embed=0.20) elif tagger: weights = FusionWeights(embed=0.3, jaccard=0.4, functional=0.3) elif text_embedder: weights = FusionWeights(embed=0.3, jaccard=0.4, text_embed=0.3) else: weights = FusionWeights(embed=0.4, jaccard=0.6) # Favor Jaccard slightly fusion = WeightedLateFusion( embeddings=embedding, adj=adj, tagger=tagger, text_embedder=text_embedder, card_data=card_data, weights=weights, aggregator="weighted", ) def candidate_fn(card: str, k: int) -> list[tuple[str, float]]: """Candidate function using fusion.""" try: results = fusion.similar(card, k=k) return results # Already returns list of (card, score) tuples except Exception: # Fallback to embedding only if card not in embedding: return [] similar = embedding.most_similar(card, topn=k) return similar if task == "deck_completion": test_decks = test_data.get("decks", []) results = { "total_decks": len(test_decks), "completed": 0, "avg_suggestions": 0.0, "avg_quality": 0.0, } total_suggestions = 0 total_quality = 0.0 for deck in test_decks: try: suggestions = suggest_additions( game=game, deck=deck, candidate_fn=candidate_fn, top_k=10, ) if suggestions: results["completed"] += 1 total_suggestions += len(suggestions) avg_score = sum(score for _, score, _ in suggestions) / len(suggestions) total_quality += avg_score except Exception: continue if results["completed"] > 0: results["avg_suggestions"] = total_suggestions / results["completed"] results["avg_quality"] = total_quality / results["completed"] return results elif task == "card_substitution": test_pairs = test_data.get("pairs", []) results = { "total_pairs": len(test_pairs), "found_substitute": 0, "avg_rank": 0.0, "p@1": 0.0, "p@5": 0.0, "p@10": 0.0, } ranks = [] p_at_1 = 0 p_at_5 = 0 p_at_10 = 0 for original, target in test_pairs: try: suggestions = suggest_replacements( game=game, deck={}, card=original, candidate_fn=candidate_fn, top_k=50, # Check even more candidates for evaluation ) found = False for rank, (card, score, _) in enumerate(suggestions, 1): if card == target: ranks.append(rank) found = True if rank <= 1: p_at_1 += 1 if rank <= 5: p_at_5 += 1 if rank <= 10: p_at_10 += 1 break if found: results["found_substitute"] += 1 except Exception: continue if results["found_substitute"] > 0: results["avg_rank"] = np.mean(ranks) if ranks else 0.0 results["p@1"] = p_at_1 / results["total_pairs"] results["p@5"] = p_at_5 / results["total_pairs"] results["p@10"] = p_at_10 / results["total_pairs"] return results elif task == "contextual_discovery": test_queries = test_data.get("queries", []) # Create discovery with fusion discovery = ContextualCardDiscovery( fusion=fusion, price_fn=None, tag_set_fn=None, archetype_staples=None, archetype_cooccurrence=None, format_cooccurrence=None, ) results = { "total_queries": len(test_queries), "found_synergies": 0, "avg_synergies": 0.0, } total_synergies = 0 for query in test_queries: try: card = query.get("card") format_name = query.get("format") archetype = query.get("archetype") expected = set(query.get("expected_synergies", [])) synergies = discovery.find_synergies( card, format=format_name, archetype=archetype, top_k=50, # Check even more candidates for evaluation ) synergy_cards = [s.card if hasattr(s, 'card') else s.get('card', '') for s in synergies] found_count = sum(1 for c in synergy_cards if c in expected) if found_count > 0: results["found_synergies"] += 1 total_synergies += found_count except Exception: continue if results["found_synergies"] > 0: results["avg_synergies"] = total_synergies / results["found_synergies"] return results return {"error": f"Unknown task: {task}"} def main() -> int: """Evaluate downstream tasks with fusion.""" parser = argparse.ArgumentParser(description="Evaluate downstream tasks with fusion") parser.add_argument("--embedding", type=str, required=True, help="Embedding file (.wv)") parser.add_argument("--pairs-csv", type=str, required=True, help="Pairs CSV for Jaccard") parser.add_argument("--game", type=str, default="magic", choices=["magic", "pokemon", "yugioh"]) parser.add_argument("--output", type=str, required=True, help="Output JSON") parser.add_argument("--test-decks", type=str, help="Test decks JSONL") parser.add_argument("--test-substitutions", type=str, help="Test substitution pairs JSON") parser.add_argument("--test-contextual", type=str, help="Test contextual queries JSON") args = parser.parse_args() if not HAS_DEPS: print("Error: Missing dependencies") return 1 # Load embedding embed_path = Path(args.embedding) if not embed_path.exists(): print(f"Error: Embedding not found: {embed_path}") return 1 print(f"Loading embedding: {embed_path}") embedding = KeyedVectors.load(str(embed_path)) print(f" Vocabulary: {len(embedding)} cards") pairs_path = Path(args.pairs_csv) if not pairs_path.exists(): print(f"Error: Pairs CSV not found: {pairs_path}") return 1 results = { "embedding": str(embed_path), "game": args.game, "tasks": {}, } # Evaluate deck completion if args.test_decks: decks_path = Path(args.test_decks) if decks_path.exists(): print("\n Evaluating deck completion with fusion...") test_decks = [] with open(decks_path) as f: for line in f: test_decks.append(json.loads(line)) completion_results = evaluate_with_fusion( embedding=embedding, pairs_csv=pairs_path, test_data={"decks": test_decks}, game=args.game, task="deck_completion", ) results["tasks"]["deck_completion"] = completion_results print(f" Completed: {completion_results.get('completed', 0)}/{completion_results.get('total_decks', 0)}") print(f" Avg quality: {completion_results.get('avg_quality', 0):.4f}") # Evaluate card substitution if args.test_substitutions: subs_path = Path(args.test_substitutions) if subs_path.exists(): print("\n Evaluating card substitution with fusion...") with open(subs_path) as f: test_pairs = json.load(f) substitution_results = evaluate_with_fusion( embedding=embedding, pairs_csv=pairs_path, test_data={"pairs": test_pairs}, game=args.game, task="card_substitution", ) results["tasks"]["card_substitution"] = substitution_results print(f" P@10: {substitution_results.get('p@10', 0):.4f}") print(f" Found: {substitution_results.get('found_substitute', 0)}/{substitution_results.get('total_pairs', 0)}") # Evaluate contextual discovery if args.test_contextual: contextual_path = Path(args.test_contextual) if contextual_path.exists(): print("\n Evaluating contextual discovery with fusion...") with open(contextual_path) as f: test_queries = json.load(f) discovery_results = evaluate_with_fusion( embedding=embedding, pairs_csv=pairs_path, test_data={"queries": test_queries}, game=args.game, task="contextual_discovery", ) results["tasks"]["contextual_discovery"] = discovery_results print(f" Found synergies: {discovery_results.get('found_synergies', 0)}/{discovery_results.get('total_queries', 0)}") # Save results output_path = Path(args.output) output_path.parent.mkdir(parents=True, exist_ok=True) with open(output_path, "w") as f: json.dump(results, f, indent=2) print(f"\n Results saved to {output_path}") return 0 if __name__ == "__main__": import sys sys.exit(main())