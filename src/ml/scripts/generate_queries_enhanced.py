#!/usr/bin/env python3 # /// script # requires-python = ">=3.11" # dependencies = [ # "pydantic-ai>=0.0.12", # ] # /// """ Enhanced query generation with better models and richer context. Uses better models and more sophisticated prompts to generate diverse, high-quality test queries. Research Basis: - Diverse test queries improve evaluation coverage - Game-aware generation ensures relevance to specific games - Better models generate higher-quality queries - Use case categorization (substitute, synergy, archetype, functional) improves task coverage References: - Test set design: https://ego4d-data.org/docs/data/annotation-guidelines/ - Query generation best practices: https://snorkel.ai/blog/data-annotation/ - Evaluation task design: Research on recommendation system evaluation frameworks """ from __future__ import annotations import argparse import json import logging import os import traceback from pathlib import Path from typing import Any, Callable try: from pydantic_ai import Agent from pydantic import BaseModel, Field HAS_PYDANTIC_AI = True except ImportError: HAS_PYDANTIC_AI = False Agent = None # type: ignore[assignment,misc] BaseModel = None # type: ignore[assignment,misc] Field = None # type: ignore[assignment,misc] try: from ml.utils.pydantic_ai_helpers import run_with_tracking HAS_PYDANTIC_AI_HELPERS = True except ImportError: HAS_PYDANTIC_AI_HELPERS = False run_with_tracking = None # type: ignore[assignment] try: from ml.utils.llm_cost_tracker import LLMCostTracker
