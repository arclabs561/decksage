#!/usr/bin/env python3 # /// script # requires-python = ">=3.11" # /// """ Batch repair all test sets in experiments directory. Finds all test sets and repairs them automatically. """ import json import logging from pathlib import Path from ml.utils.logging_config import setup_script_logging logger = setup_script_logging() # Import repair function import sys from pathlib import Path as P script_dir = P(__file__).parent src_dir = script_dir.parent.parent if str(src_dir) not in sys.path: sys.path.insert(0, str(src_dir)) from ml.scripts.repair_test_sets import repair_test_set, detect_game_from_path def find_all_test_sets(experiments_dir: Path) -> list[tuple[Path, str]]: """Find all test sets and detect their games.""" test_sets = [] # Find all JSON files that look like test sets for json_file in experiments_dir.rglob("test_set*.json"): # Skip checkpoint and repaired files if "checkpoint" in json_file.name or "repaired" in json_file.parent.name: continue # Skip already repaired files if json_file.parent.name == "repaired": continue try: with open(json_file) as f: data = json.load(f) game = detect_game_from_path(json_file, data) test_sets.append((json_file, game)) except Exception as e: logger.warning(f"Could not read {json_file}: {e}") return test_sets def main() -> int: """Batch repair all test sets.""" import argparse parser = argparse.ArgumentParser(description="Batch repair all test sets") parser.add_argument("--dir", type=str, default="experiments", help="Directory containing test sets") parser.add_argument("--output-dir", type=str, help="Output directory (default: {dir}/repaired)") parser.add_argument("--dry-run", action="store_true", help="Show what would be repaired without doing it") args = parser.parse_args() experiments_dir = Path(args.dir) output_dir = Path(args.output_dir) if args.output_dir else experiments_dir / "repaired" if not experiments_dir.exists(): logger.error(f"Directory not found: {experiments_dir}") return 1 test_sets = find_all_test_sets(experiments_dir) logger.info(f"Found {len(test_sets)} test sets to repair") if args.dry_run: print("\n=== Dry Run - Test Sets to Repair ===") for test_set_path, game in test_sets: print(f" {test_set_path.name} ({game})") return 0 output_dir.mkdir(parents=True, exist_ok=True) all_stats = {} for test_set_path, game in test_sets: logger.info(f"\n{'='*60}") logger.info(f"Repairing: {test_set_path.name} ({game})") output_path = output_dir / test_set_path.name try: stats = repair_test_set(test_set_path, output_path, game=game) all_stats[test_set_path.name] = stats logger.info(f" Repaired: {stats['queries_repaired']}/{stats['total_queries']} queries") logger.info(f" Removed: {stats['cross_game_removed']} cross-game cards") except Exception as e: logger.error(f" Error: Failed: {e}") import traceback logger.debug(traceback.format_exc()) # Summary print("\n" + "="*60) print("=== Batch Repair Summary ===") print(f"Test sets processed: {len(all_stats)}") total_queries = sum(s['total_queries'] for s in all_stats.values()) total_repaired = sum(s['queries_repaired'] for s in all_stats.values()) total_cross_game = sum(s['cross_game_removed'] for s in all_stats.values()) total_duplicates = sum(s['duplicates_fixed'] for s in all_stats.values()) print(f"Total queries: {total_queries}") print(f"Queries repaired: {total_repaired} ({100*total_repaired/total_queries:.1f}%)") print(f"Cross-game cards removed: {total_cross_game}") print(f"Duplicates fixed: {total_duplicates}") print(f"\n All repaired test sets saved to: {output_dir}") return 0 if __name__ == "__main__": import sys sys.exit(main())