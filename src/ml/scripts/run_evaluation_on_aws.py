#!/usr/bin/env python3 """ Run embedding evaluation on AWS EC2 instance. This script uploads the evaluation script and data to S3, then executes it on an EC2 instance via SSM to avoid local dependency issues. """ # /// script # requires-python = ">=3.11" # dependencies = [ # "boto3>=1.34.0", # ] # /// import json import sys import time from pathlib import Path try: import boto3 HAS_BOTO3 = True except ImportError: HAS_BOTO3 = False print("Error: boto3 not available", file=sys.stderr) def upload_file_to_s3(local_path: Path, s3_key: str, bucket: str = "games-collections") -> bool: """Upload file to S3.""" s3 = boto3.client("s3") try: s3.upload_file(str(local_path), bucket, s3_key) print(f" Uploaded {local_path.name} to s3://{bucket}/{s3_key}") return True except Exception as e: print(f"Error: Failed to upload {local_path.name}: {e}", file=sys.stderr) return False def create_ec2_instance( instance_type: str = "t3.medium", use_spot: bool = True, spot_max_price: str | None = "0.10", fallback_to_ondemand: bool = True, ) -> str | None: """Create EC2 instance for computation.""" ec2 = boto3.client("ec2") # AMI for Amazon Linux 2023 (us-east-1) ami_id = "ami-08fa3ed5577079e64" # User data to install Python and dependencies user_data = """#!/bin/bash yum update -y yum install -y python3 python3-pip git python3 -m pip install --upgrade pip || pip3 install --upgrade pip || true python3 -m pip install pandas numpy gensim boto3 || pip3 install pandas numpy gensim boto3 || true """ launch_spec = { "ImageId": ami_id, "InstanceType": instance_type, "MinCount": 1, "MaxCount": 1, "UserData": user_data, "IamInstanceProfile": {"Name": "EC2-SSM-InstanceProfile"}, } if use_spot and spot_max_price: launch_spec["InstanceMarketOptions"] = { "MarketType": "spot", "SpotOptions": { "MaxPrice": spot_max_price, "SpotInstanceType": "one-time", "InstanceInterruptionBehavior": "terminate", }, } try: if use_spot: print(f"Creating spot instance ({instance_type}, max ${spot_max_price or 'on-demand'}/hr)...") response = ec2.run_instances(**launch_spec) else: print(f"Creating on-demand instance ({instance_type})...") response = ec2.run_instances(**launch_spec) instance_id = response["Instances"][0]["InstanceId"] print(f" Created instance: {instance_id}") return instance_id except Exception as e: if use_spot and fallback_to_ondemand: print(f"Warning: Spot instance failed: {e}") print("Falling back to on-demand...") launch_spec.pop("InstanceMarketOptions", None) try: response = ec2.run_instances(**launch_spec) instance_id = response["Instances"][0]["InstanceId"] print(f" Created on-demand instance: {instance_id}") return instance_id except Exception as e2: print(f"Error: On-demand also failed: {e2}", file=sys.stderr) return None else: print(f"Error: Failed to create instance: {e}", file=sys.stderr) return None def wait_for_ssm_ready(instance_id: str, timeout: int = 300) -> bool: """Wait for SSM to be ready.""" ssm = boto3.client("ssm") print(f"Waiting for SSM to be ready on {instance_id}...") start_time = time.time() while time.time() - start_time < timeout: try: response = ssm.describe_instance_information( Filters=[{"Key": "InstanceIds", "Values": [instance_id]}] ) if response.get("InstanceInformationList"): time.sleep(10) print(" SSM is ready") return True except Exception: pass time.sleep(5) print(".", end="", flush=True) print("\nWarning: SSM timeout") return False def run_command_on_instance(instance_id: str, command: str, timeout: int = 3600) -> tuple[int, str, str]: """Run command on EC2 instance via SSM.""" ssm = boto3.client("ssm") print(f"Running command on {instance_id}...") print(f" Command: {command[:100]}...") try: response = ssm.send_command( InstanceIds=[instance_id], DocumentName="AWS-RunShellScript", Parameters={"commands": [command]}, TimeoutSeconds=timeout, ) command_id = response["Command"]["CommandId"] # Wait for command to complete while True: time.sleep(5) result = ssm.get_command_invocation( CommandId=command_id, InstanceId=instance_id, ) status = result["Status"] if status in ["Success", "Failed", "Cancelled", "TimedOut"]: stdout = result.get("StandardOutputContent", "") stderr = result.get("StandardErrorContent", "") exit_code = 0 if status == "Success" else 1 return exit_code, stdout, stderr print(".", end="", flush=True) except Exception as e: print(f"Error: Command failed: {e}", file=sys.stderr) return 1, "", str(e) def download_from_s3(s3_key: str, local_path: Path, bucket: str = "games-collections") -> bool: """Download file from S3.""" s3 = boto3.client("s3") try: local_path.parent.mkdir(parents=True, exist_ok=True) s3.download_file(bucket, s3_key, str(local_path)) print(f" Downloaded {s3_key} to {local_path}") return True except Exception as e: print(f"Error: Failed to download: {e}", file=sys.stderr) return False def main() -> int: """Run evaluation on AWS EC2.""" if not HAS_BOTO3: print("Error: boto3 not available", file=sys.stderr) return 1 bucket = "games-collections" # Paths script_path = Path("src/ml/scripts/evaluate_all_embeddings.py") s3_script_key = "scripts/evaluate_all_embeddings.py" # Upload script to S3 print("=" * 70) print("Step 1: Upload evaluation script to S3") print("=" * 70) if not upload_file_to_s3(script_path, s3_script_key, bucket): return 1 # Upload name_normalizer module print("\n" + "=" * 70) print("Step 2: Upload name_normalizer module") print("=" * 70) name_normalizer_path = Path("src/ml/utils/name_normalizer.py") s3_normalizer_key = "scripts/name_normalizer.py" if not upload_file_to_s3(name_normalizer_path, s3_normalizer_key, bucket): print("Warning: Warning: Could not upload name_normalizer, continuing...") # Create EC2 instance print("\n" + "=" * 70) print("Step 3: Create EC2 instance") print("=" * 70) instance_id = create_ec2_instance( instance_type="t3.medium", use_spot=True, spot_max_price="0.10", fallback_to_ondemand=True, ) if not instance_id: return 1 # Wait for SSM if not wait_for_ssm_ready(instance_id): print("Warning: Continuing anyway...") # Wait for user_data to complete print("\n" + "=" * 70) print("Step 3.5: Wait for user_data to complete") print("=" * 70) print("Waiting for Python installation to complete...") wait_cmd = "while ! command -v python3 &> /dev/null; do sleep 5; done && echo 'Python ready'" exit_code, stdout, stderr = run_command_on_instance(instance_id, wait_cmd, timeout=300) if exit_code == 0: print(" Python is ready") else: print("Warning: Python check failed, continuing anyway...") # Verify dependencies print("\n" + "=" * 70) print("Step 4: Verify dependencies") print("=" * 70) check_cmd = "python3 -c 'import pandas, numpy, gensim, boto3; print(\"All dependencies available\")' 2>&1 || echo 'Need to install'" exit_code, stdout, stderr = run_command_on_instance(instance_id, check_cmd) print(stdout) if "Need to install" in stdout or exit_code != 0: print("Installing dependencies...") # Try pip3 first, fallback to python3 -m pip install_cmd = "python3 -m pip install pandas numpy gensim boto3 2>&1 || pip3 install pandas numpy gensim boto3 2>&1 || python3 -m ensurepip --upgrade && python3 -m pip install pandas numpy gensim boto3" exit_code, stdout, stderr = run_command_on_instance(instance_id, install_cmd, timeout=600) if exit_code != 0: print(f"Warning: Install warning: {stderr}") print(stdout) # Verify installation print("Verifying installation...") verify_cmd = "python3 -c 'import pandas, numpy, gensim, boto3; print(\"All dependencies available\")'" exit_code, stdout, stderr = run_command_on_instance(instance_id, verify_cmd, timeout=60) if exit_code != 0: print(f"Error: Verification failed: {stderr}", file=sys.stderr) return 1 print(" Dependencies verified") else: print(" Dependencies already installed") # Download script and data print("\n" + "=" * 70) print("Step 5: Download script and data on instance") print("=" * 70) # Use Python with boto3 to download files (AWS CLI has dependency conflicts) download_script = f"""python3 << 'PYDOWNLOAD' import boto3 import os s3 = boto3.client('s3') bucket = '{bucket}' os.makedirs('/tmp/evaluation', exist_ok=True) os.makedirs('/tmp/evaluation/embeddings', exist_ok=True) files_to_download = [ ('{s3_script_key}', '/tmp/evaluation/evaluate_all_embeddings.py'), ('{s3_normalizer_key}', '/tmp/evaluation/name_normalizer.py'), ('processed/test_set_unified_magic.json', '/tmp/evaluation/test_set.json'), ('processed/name_mapping.json', '/tmp/evaluation/name_mapping.json'), ('embeddings/magic_128d_test_pecanpy.wv', '/tmp/evaluation/embeddings/magic_128d_test_pecanpy.wv'), ('processed/pairs_large.csv', '/tmp/evaluation/pairs_large.csv'), ] for s3_key, local_path in files_to_download: try: s3.download_file(bucket, s3_key, local_path) print(f' Downloaded {{s3_key}}') except Exception as e: print(f'Warning: Could not download {{s3_key}}: {{e}}') print('Download complete') PYDOWNLOAD """ exit_code, stdout, stderr = run_command_on_instance(instance_id, download_script, timeout=1800) if exit_code != 0: print(f"Warning: Download warning: {stderr}") print(stdout[:500]) # Print first 500 chars # Create standalone evaluation script print("\n" + "=" * 70) print("Step 6: Create standalone evaluation script") print("=" * 70) # Create directory structure for ml.utils setup_cmd = """ mkdir -p /tmp/evaluation/ml/utils cd /tmp/evaluation # Copy name_normalizer to proper location if [ -f name_normalizer.py ]; then cp name_normalizer.py ml/utils/name_normalizer.py touch ml/__init__.py touch ml/utils/__init__.py fi """ exit_code, stdout, stderr = run_command_on_instance(instance_id, setup_cmd) if exit_code != 0: print(f"Warning: Setup warning: {stderr}") # Create a wrapper script that sets up Python path and runs evaluation wrapper_script = """#!/usr/bin/env python3 import sys import os # Add current directory to path (so ml module can be found) sys.path.insert(0, '/tmp/evaluation') # Try to import name_normalizer from ml.utils try: from ml.utils.name_normalizer import NameMapper except ImportError: # Create minimal name_normalizer if import fails import json class NameMapper: def __init__(self, mapping=None, mapping_path=None): if mapping_path and os.path.exists(mapping_path): with open(mapping_path) as f: data = json.load(f) self.mapping = data.get('mapping', {}) else: self.mapping = {} or mapping or {} def map_name(self, name): return self.mapping.get(name, name) def map_names(self, names): return [self.map_name(n) for n in names] @classmethod def load_from_file(cls, path): return cls(mapping_path=path) # Create module structure import types ml = types.ModuleType('ml') ml.utils = types.ModuleType('ml.utils') ml.utils.name_normalizer = types.ModuleType('ml.utils.name_normalizer') ml.utils.name_normalizer.NameMapper = NameMapper sys.modules['ml'] = ml sys.modules['ml.utils'] = ml.utils sys.modules['ml.utils.name_normalizer'] = ml.utils.name_normalizer # Now run the evaluation script with open('/tmp/evaluation/evaluate_all_embeddings.py') as f: code = f.read() exec(code, {'__name__': '__main__', '__file__': '/tmp/evaluation/evaluate_all_embeddings.py'}) """ # Write wrapper script write_wrapper_cmd = """cat > /tmp/evaluation/run_evaluation.py << 'EOFWRAPPER' #!/usr/bin/env python3 import sys import os # Add current directory to path (so ml module can be found) sys.path.insert(0, '/tmp/evaluation') # Try to import name_normalizer from ml.utils try: from ml.utils.name_normalizer import NameMapper except ImportError: # Create minimal name_normalizer if import fails import json class NameMapper: def __init__(self, mapping=None, mapping_path=None): if mapping_path and os.path.exists(mapping_path): with open(mapping_path) as f: data = json.load(f) self.mapping = data.get('mapping', {}) else: self.mapping = {} or mapping or {} def map_name(self, name): return self.mapping.get(name, name) def map_names(self, names): return [self.map_name(n) for n in names] @classmethod def load_from_file(cls, path): return cls(mapping_path=path) # Create module structure import types ml = types.ModuleType('ml') ml.utils = types.ModuleType('ml.utils') ml.utils.name_normalizer = types.ModuleType('ml.utils.name_normalizer') ml.utils.name_normalizer.NameMapper = NameMapper sys.modules['ml'] = ml sys.modules['ml.utils'] = ml.utils sys.modules['ml.utils.name_normalizer'] = ml.utils.name_normalizer # Now run the evaluation script with open('/tmp/evaluation/evaluate_all_embeddings.py') as f: code = f.read() exec(code, {'__name__': '__main__', '__file__': '/tmp/evaluation/evaluate_all_embeddings.py'}) EOFWRAPPER chmod +x /tmp/evaluation/run_evaluation.py """ exit_code, stdout, stderr = run_command_on_instance(instance_id, write_wrapper_cmd) if exit_code != 0: print(f"Warning: Wrapper creation warning: {stderr}") # Run evaluation print("\n" + "=" * 70) print("Step 7: Run evaluation") print("=" * 70) run_cmd = """ cd /tmp/evaluation python3 run_evaluation.py \ --test-set test_set.json \ --name-mapping name_mapping.json \ --pairs-csv pairs_large.csv \ --embeddings-dir embeddings \ --output results.json """ exit_code, stdout, stderr = run_command_on_instance(instance_id, run_cmd, timeout=3600) print(stdout) if stderr: print("STDERR:", stderr, file=sys.stderr) if exit_code != 0: print(f"Error: Evaluation failed: {stderr}", file=sys.stderr) # Still try to download results if they exist # Download results print("\n" + "=" * 70) print("Step 8: Download results") print("=" * 70) download_results_cmd = "cat /tmp/evaluation/results.json 2>&1 || echo 'Results file not found'" exit_code, stdout, stderr = run_command_on_instance(instance_id, download_results_cmd) if exit_code == 0 and stdout and "Results file not found" not in stdout: from ml.utils.paths import PATHS local_output = PATHS.experiments / "embedding_evaluation_with_mapping.json" local_output.parent.mkdir(parents=True, exist_ok=True) with open(local_output, "w") as f: f.write(stdout) print(f" Results saved to {local_output}") # Also upload to S3 try: s3 = boto3.client("s3") s3.upload_file(str(local_output), bucket, "processed/embedding_evaluation_with_mapping.json") print(f" Uploaded to s3://{bucket}/processed/embedding_evaluation_with_mapping.json") except Exception as e: print(f"Warning: Could not upload to S3: {e}") else: print(f"Warning: Could not download results: {stderr}") # Terminate instance print("\n" + "=" * 70) print("Step 9: Terminate instance") print("=" * 70) ec2 = boto3.client("ec2") try: ec2.terminate_instances(InstanceIds=[instance_id]) print(f" Terminated instance {instance_id}") except Exception as e: print(f"Warning: Could not terminate: {e}") print("\n" + "=" * 70) print(" Evaluation complete!") print("=" * 70) return 0 if __name__ == "__main__": sys.exit(main())