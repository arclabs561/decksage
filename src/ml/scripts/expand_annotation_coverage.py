#!/usr/bin/env python3 # /// script # requires-python = ">=3.11" # dependencies = [ # "pyyaml>=6.0", # ] # /// """ Expand annotation coverage by identifying gaps. Analyzes: 1. Which cards/pairs need more annotations 2. Which similarity types are underrepresented 3. Which games need more coverage 4. Which downstream tasks need more support """ from __future__ import annotations import argparse import json from collections import Counter, defaultdict from pathlib import Path from typing import Any try: import yaml HAS_YAML = True except ImportError: HAS_YAML = False import sys script_dir = Path(__file__).parent src_dir = script_dir.parent.parent if str(src_dir) not in sys.path: sys.path.insert(0, str(src_dir)) from ml.utils.annotation_utils import load_similarity_annotations, load_hand_annotations def analyze_annotation_coverage(annotation_paths: list[Path]) -> dict[str, Any]: """Analyze annotation coverage across all files.""" all_annotations = [] all_cards = set() similarity_types = Counter() games = Counter() downstream_fields = { "role_match": 0, "archetype_context": 0, "format_context": 0, "substitution_quality": 0, } for ann_path in annotation_paths: if not ann_path.exists(): continue if ann_path.suffix == ".yaml": annotations = load_hand_annotations(ann_path) else: annotations = load_similarity_annotations(ann_path) for ann in annotations: all_annotations.append(ann) all_cards.add(ann.get("card1", "")) all_cards.add(ann.get("card2", "")) similarity_types[ann.get("similarity_type", "unknown")] += 1 # Check downstream fields if ann.get("role_match") is not None: downstream_fields["role_match"] += 1 if ann.get("archetype_context"): downstream_fields["archetype_context"] += 1 if ann.get("format_context"): downstream_fields["format_context"] += 1 if ann.get("substitution_quality"): downstream_fields["substitution_quality"] += 1 # Find pairs that need more annotations pair_counts = Counter() for ann in all_annotations: card1 = ann.get("card1") card2 = ann.get("card2") if card1 and card2: pair = tuple(sorted([card1, card2])) pair_counts[pair] += 1 # Pairs with only one annotation (need more for IAA) single_annotation_pairs = [pair for pair, count in pair_counts.items() if count == 1] return { "total_annotations": len(all_annotations), "unique_cards": len(all_cards), "unique_pairs": len(pair_counts), "single_annotation_pairs": len(single_annotation_pairs), "similarity_type_distribution": dict(similarity_types), "downstream_field_coverage": downstream_fields, "coverage_gaps": { "need_more_annotations": single_annotation_pairs[:20], # Top 20 "underrepresented_types": [ st for st, count in similarity_types.items() if count < len(all_annotations) * 0.1 # Less than 10% of total ], }, } def main() -> int: parser = argparse.ArgumentParser(description="Analyze annotation coverage") parser.add_argument("--annotations-dir", type=str, default="annotations", help="Annotations directory") parser.add_argument("--output", type=str, help="Output JSON report") args = parser.parse_args() annotations_dir = Path(args.annotations_dir) if not annotations_dir.exists(): print(f"Error: Annotations directory not found: {annotations_dir}") return 1 # Find all annotation files annotation_files = ( list(annotations_dir.glob("*.yaml")) + list(annotations_dir.glob("*.jsonl")) + list(annotations_dir.glob("**/*similarity*.jsonl")) ) print("=" * 70) print("ANNOTATION COVERAGE ANALYSIS") print("=" * 70) print() print(f"Found {len(annotation_files)} annotation files") print() results = analyze_annotation_coverage(annotation_files) print(f" Coverage Statistics:") print(f" Total annotations: {results['total_annotations']}") print(f" Unique cards: {results['unique_cards']}") print(f" Unique pairs: {results['unique_pairs']}") print(f" Pairs with single annotation: {results['single_annotation_pairs']}") print() print(f"ðŸ“ˆ Similarity Type Distribution:") for st, count in sorted(results['similarity_type_distribution'].items(), key=lambda x: -x[1]): pct = count / results['total_annotations'] * 100 if results['total_annotations'] > 0 else 0 print(f" {st}: {count} ({pct:.1f}%)") print() print(f"ðŸ“‹ Downstream Field Coverage:") for field, count in results['downstream_field_coverage'].items(): pct = count / results['total_annotations'] * 100 if results['total_annotations'] > 0 else 0 print(f" {field}: {count} ({pct:.1f}%)") print() if results['coverage_gaps']['underrepresented_types']: print(f"Warning: Underrepresented similarity types:") for st in results['coverage_gaps']['underrepresented_types']: print(f" - {st}") print() # Save report if args.output: with open(args.output, "w") as f: json.dump(results, f, indent=2, default=str) print(f"âœ“ Saved report to {args.output}") print("=" * 70) print(" Analysis complete!") print("=" * 70) return 0 if __name__ == "__main__": import sys sys.exit(main())