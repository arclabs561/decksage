#!/usr/bin/env python3 # /// script # requires-python = ">=3.11" # dependencies = [ # "pydantic-ai>=0.0.12", # ] # /// """Continue test set expansion in smaller chunks with validation.""" import json import sys from pathlib import Path sys.path.insert(0, str(Path(__file__).parent.parent.parent)) # Import expansion function try: from ml.scripts.expand_test_set_with_llm import expand_test_set HAS_EXPAND = True except ImportError: HAS_EXPAND = False print("Error: expand_test_set_with_llm not available") GAMES = { "magic": { "name": "Magic: The Gathering", "target": 200, "test_set": "experiments/test_set_unified_magic.json", }, "pokemon": { "name": "Pok√©mon TCG", "target": 100, "test_set": "experiments/test_set_unified_pokemon.json", }, "yugioh": { "name": "Yu-Gi-Oh!", "target": 100, "test_set": "experiments/test_set_unified_yugioh.json", }, } def expand_game_chunked(game: str, chunk_size: int = 25): """Expand test set for a game in chunks.""" if not HAS_EXPAND: print("Error: Expansion not available") return game_info = GAMES[game] existing_path = Path(game_info["test_set"]) output_path = existing_path target_size = game_info["target"] # Check current size current_size = 0 if existing_path.exists(): with open(existing_path) as f: data = json.load(f) queries = data.get("queries", data) if isinstance(data, dict) else data current_size = len(queries) if isinstance(queries, dict) else 0 num_new = max(0, target_size - current_size) if num_new <= 0: print(f" {game_info['name']}: Already at target ({current_size})") return print(f" {game_info['name']}: {current_size}/{target_size} - Adding {num_new} in chunks of {chunk_size}") # Process in chunks chunks = (num_new + chunk_size - 1) // chunk_size for chunk_idx in range(chunks): chunk_num = min(chunk_size, num_new - (chunk_idx * chunk_size)) print(f" Chunk {chunk_idx + 1}/{chunks} ({chunk_num} queries)...") result = expand_test_set( existing_test_set_path=existing_path if chunk_idx == 0 else output_path, output_path=output_path, num_new_queries=chunk_num, num_judges=3, batch_size=10, parallel_judges=True, game=game, ) if result.get("successfully_labeled", 0) > 0: labeled = result.get("successfully_labeled", 0) print(f" Labeled {labeled} queries") else: print(f" Warning: No queries labeled in this chunk") # Validate after each chunk if output_path.exists(): with open(output_path) as f: data = json.load(f) queries = data.get("queries", data) if isinstance(data, dict) else data current = len(queries) if isinstance(queries, dict) else 0 print(f" Progress: {current}/{target_size} queries") if __name__ == "__main__": import argparse parser = argparse.ArgumentParser() parser.add_argument("--game", type=str, choices=list(GAMES.keys()), required=True) parser.add_argument("--chunk-size", type=int, default=25) args = parser.parse_args() expand_game_chunked(args.game, args.chunk_size)
