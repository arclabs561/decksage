#!/usr/bin/env python3 # /// script # requires-python = ">=3.11" # dependencies = [ # "numpy", # "scipy", # ] # /// """ Optimize fusion weights using test set evaluation. Uses scipy.optimize to find optimal weights for combining: - Embedding similarity - Jaccard co-occurrence - Functional tags (if available) - Text embeddings (if available) - Other signals After embeddings improve, run this to find best fusion weights. """ from __future__ import annotations import argparse import json import logging from pathlib import Path from typing import Any try: import numpy as np from scipy.optimize import minimize HAS_OPTIMIZATION = True except ImportError: HAS_OPTIMIZATION = False logging.basicConfig(level=logging.INFO) logger = logging.getLogger(__name__) def load_embeddings(embed_path: Path): """Load embeddings.""" try: from gensim.models import KeyedVectors return KeyedVectors.load(str(embed_path)) except Exception as e: logger.error(f"Failed to load embeddings: {e}") return None def load_jaccard_graph(pairs_csv: Path | None = None, graph_db: Path | None = None, game: str | None = None) -> dict[str, set[str]]: """Load Jaccard graph (uses shared implementation).""" from ml.utils.shared_operations import load_jaccard_graph as shared_load return shared_load(pairs_csv=pairs_csv, graph_db=graph_db, game=game) def jaccard_similarity(set1: set[str], set2: set[str]) -> float: """Compute Jaccard similarity.""" if not set1 or not set2: return 0.0 intersection = len(set1 & set2) union = len(set1 | set2) return intersection / union if union > 0 else 0.0 def evaluate_fusion_weights( weights: np.ndarray, wv: Any, adj: dict[str, set[str]], test_set: dict[str, dict[str, Any]], top_k: int = 10, ) -> float: """ Evaluate fusion weights and return negative P@10 (for minimization). Weights: [embed_weight, jaccard_weight, ...] """ embed_weight = weights[0] jaccard_weight = weights[1] # Normalize weights total = embed_weight + jaccard_weight if total == 0: return 1.0 # Worst possible score embed_weight /= total jaccard_weight /= total scores = [] for query, labels in test_set.items(): if query not in wv and query not in adj: continue # Get embedding scores embed_scores = {} if query in wv and embed_weight > 0: try: similar = wv.most_similar(query, topn=top_k * 2) for card, sim in similar: embed_scores[card] = float(sim) * embed_weight except KeyError: pass # Get Jaccard scores jaccard_scores = {} if query in adj and jaccard_weight > 0: query_neighbors = adj[query] for candidate in adj.keys(): if candidate == query: continue candidate_neighbors = adj[candidate] sim = jaccard_similarity(query_neighbors, candidate_neighbors) jaccard_scores[candidate] = sim * jaccard_weight # Combine scores all_candidates = set(embed_scores.keys()) | set(jaccard_scores.keys()) combined_scores = {} for candidate in all_candidates: combined_scores[candidate] = ( embed_scores.get(candidate, 0.0) + jaccard_scores.get(candidate, 0.0) ) # Get top-k top_candidates = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)[:top_k] candidates = [card for card, _ in top_candidates] # Compute P@10 relevance_weights = { "highly_relevant": 1.0, "relevant": 0.75, "somewhat_relevant": 0.5, "marginally_relevant": 0.25, } score = 0.0 for card in candidates: for level, weight in relevance_weights.items(): if card in labels.get(level, []): score += weight break scores.append(score / top_k) if not scores: return 1.0 avg_score = np.mean(scores) return -avg_score # Negative for minimization def optimize_fusion( embed_path: Path, pairs_csv: Path, test_set_path: Path, top_k: int = 10, ) -> dict[str, Any]: """Optimize fusion weights.""" if not HAS_OPTIMIZATION: logger.error("scipy required for optimization") return {} # Load data logger.info("Loading embeddings...") wv = load_embeddings(embed_path) if not wv: return {} logger.info("Loading Jaccard graph...") adj = load_jaccard_graph(pairs_csv) logger.info("Loading test set...") with open(test_set_path) as f: data = json.load(f) test_set = data.get("queries", data) if isinstance(data, dict) else data logger.info(f"Optimizing fusion weights on {len(test_set)} queries...") # Initial guess: equal weights initial_weights = np.array([0.5, 0.5]) # Bounds: weights must be non-negative bounds = [(0.0, 1.0), (0.0, 1.0)] # Optimize result = minimize( evaluate_fusion_weights, initial_weights, args=(wv, adj, test_set, top_k), method='L-BFGS-B', bounds=bounds, options={'maxiter': 100}, ) if not result.success: logger.warning(f"Optimization did not converge: {result.message}") optimal_weights = result.x # Normalize total = optimal_weights.sum() if total > 0: optimal_weights = optimal_weights / total # Evaluate final score final_score = -evaluate_fusion_weights(optimal_weights, wv, adj, test_set, top_k) logger.info(f" Optimization complete!") logger.info(f" Optimal weights: embed={optimal_weights[0]:.3f}, jaccard={optimal_weights[1]:.3f}") logger.info(f" Final P@10: {final_score:.4f}") return { "embed_weight": float(optimal_weights[0]), "jaccard_weight": float(optimal_weights[1]), "p@10": float(final_score), "optimization_success": result.success, "message": result.message, } def main() -> int: """Optimize fusion weights.""" parser = argparse.ArgumentParser(description="Optimize fusion weights") parser.add_argument("--embedding", type=str, required=True, help="Embedding file (.wv)") parser.add_argument("--pairs-csv", type=str, required=True, help="Pairs CSV for Jaccard") parser.add_argument("--test-set", type=str, required=True, help="Test set JSON") parser.add_argument("--output", type=str, default="experiments/optimal_fusion_weights.json", help="Output JSON") parser.add_argument("--top-k", type=int, default=10, help="Top K for evaluation") args = parser.parse_args() if not HAS_OPTIMIZATION: logger.error("scipy required: pip install scipy") return 1 result = optimize_fusion( Path(args.embedding), Path(args.pairs_csv), Path(args.test_set), top_k=args.top_k, ) if not result: return 1 # Save output_path = Path(args.output) output_path.parent.mkdir(parents=True, exist_ok=True) with open(output_path, "w") as f: json.dump(result, f, indent=2) logger.info(f" Saved to {output_path}") return 0 if __name__ == "__main__": import sys from ml.utils.shared_operations import load_embeddings, get_embedding_path sys.exit(main())