#!/usr/bin/env python3 # /// script # requires-python = ">=3.11" # dependencies = [ # "pandas>=2.0.0", # "numpy<2.0.0", # "gensim>=4.3.0", # ] # /// """Evaluate game-specific vs multi-game embeddings.""" import json import sys from pathlib import Path sys.path.insert(0, str(Path(__file__).parent.parent.parent)) from gensim.models import KeyedVectors from ml.utils.evaluation import evaluate_with_confidence from ml.utils.name_normalizer import NameMapper GAMES = { "magic": { "test_set": "experiments/test_set_unified_magic.json", "game_specific": "data/embeddings/magic_game_specific.wv", "multi_game": "data/embeddings/multi_game_unified.wv", }, "pokemon": { "test_set": "experiments/test_set_unified_pokemon.json", "game_specific": "data/embeddings/pokemon_game_specific.wv", "multi_game": "data/embeddings/multi_game_unified.wv", }, "yugioh": { "test_set": "experiments/test_set_unified_yugioh.json", "game_specific": "data/embeddings/yugioh_game_specific.wv", "multi_game": "data/embeddings/multi_game_unified.wv", }, } def evaluate_embedding(emb_path: Path, test_set_path: Path, game: str): """Evaluate an embedding on a game's test set.""" if not emb_path.exists(): return None print(f" Evaluating {emb_path.name}...") # Load embedding wv = KeyedVectors.load(str(emb_path)) # Load test set with open(test_set_path) as f: data = json.load(f) queries = data.get("queries", data) if isinstance(data, dict) else data # Keep dict format (evaluate_with_confidence expects dict format) test_queries = {} for query, labels in queries.items(): if isinstance(labels, dict): # Keep the dict format for evaluate_with_confidence test_queries[query] = labels # Load name mapper name_mapping_path = Path("data/processed/name_mapping.json") name_mapper = None if name_mapping_path.exists(): name_mapper = NameMapper.load_from_file(name_mapping_path) # Create similarity function def similarity_func(query: str, k: int): mapped_query = name_mapper.map_name(query) if name_mapper else query if mapped_query not in wv: # Try original query if mapping failed if query not in wv: return [] mapped_query = query similar = wv.most_similar(mapped_query, topn=k) # Return as list of (card, score) tuples return [(card, float(score)) for card, score in similar] # Evaluate try: results = evaluate_with_confidence( test_set=test_queries, similarity_func=similarity_func, top_k=10, n_bootstrap=100, ) p_at_10 = results.get("p@10", results.get("p_at_10", 0.0)) p_at_10_ci = results.get("p@10_ci", results.get("p_at_10_ci", [0.0, 0.0])) mrr = results.get("mrr", results.get("mrr@10", 0.0)) return { "p@10": p_at_10, "p@10_ci": p_at_10_ci if isinstance(p_at_10_ci, list) else [p_at_10, p_at_10], "mrr": mrr, "n_queries": len(test_queries), } except Exception as e: print(f" Error: Error: {e}") return None def main(): """Compare game-specific vs multi-game.""" print("=" * 70) print("GAME-SPECIFIC VS MULTI-GAME EVALUATION") print("=" * 70) print() all_results = {} for game, config in GAMES.items(): print(f"\n {game.upper()}:") test_set_path = Path(config["test_set"]) if not test_set_path.exists(): print(f" ⏭️ Test set not found: {test_set_path}") continue game_specific_path = Path(config["game_specific"]) multi_game_path = Path(config["multi_game"]) results = {} # Evaluate game-specific if game_specific_path.exists(): game_specific_result = evaluate_embedding(game_specific_path, test_set_path, game) if game_specific_result: results["game_specific"] = game_specific_result p_at_10 = game_specific_result["p@10"] ci = game_specific_result["p@10_ci"] print(f" Game-specific: P@10={p_at_10:.3f} [{ci[0]:.3f}, {ci[1]:.3f}]") else: print(f" ⏭️ Game-specific embedding not found") # Evaluate multi-game if multi_game_path.exists(): multi_game_result = evaluate_embedding(multi_game_path, test_set_path, game) if multi_game_result: results["multi_game"] = multi_game_result p_at_10 = multi_game_result["p@10"] ci = multi_game_result["p@10_ci"] print(f" Multi-game: P@10={p_at_10:.3f} [{ci[0]:.3f}, {ci[1]:.3f}]") else: print(f" ⏭️ Multi-game embedding not found") if results: all_results[game] = results # Save results output_path = Path("experiments/game_specific_vs_multigame.json") with open(output_path, "w") as f: json.dump(all_results, f, indent=2) print(f"\n Saved to {output_path}") # Summary print("\n" + "=" * 70) print("SUMMARY") print("=" * 70) print() for game, results in all_results.items(): print(f"{game.upper()}:") if "game_specific" in results and "multi_game" in results: gs_p = results["game_specific"]["p@10"] mg_p = results["multi_game"]["p@10"] diff = gs_p - mg_p winner = "Game-specific" if diff > 0 else "Multi-game" print(f" Game-specific: P@10={gs_p:.3f}") print(f" Multi-game: P@10={mg_p:.3f}") print(f" Winner: {winner} (diff: {diff:+.3f})") print() if __name__ == "__main__": main()
