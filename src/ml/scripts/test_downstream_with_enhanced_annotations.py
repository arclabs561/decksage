#!/usr/bin/env python3 # /// script # requires-python = ">=3.11" # dependencies = [ # "pyyaml>=6.0", # "gensim>=4.3.0", # ] # /// """ Test downstream tasks with enhanced annotations. Verifies that enhanced annotation fields (role_match, archetype_context, etc.) are properly used by downstream tasks. """ from __future__ import annotations import argparse import json from pathlib import Path from typing import Any try: import yaml from gensim.models import KeyedVectors HAS_DEPS = True except ImportError: HAS_DEPS = False print("Install dependencies: pip install pyyaml gensim") import sys script_dir = Path(__file__).parent src_dir = script_dir.parent.parent if str(src_dir) not in sys.path: sys.path.insert(0, str(src_dir)) from ml.utils.annotation_utils import load_hand_annotations, extract_substitution_pairs_from_annotations def analyze_enhanced_annotations(annotation_path: Path) -> dict[str, Any]: """Analyze enhanced annotations for downstream task support.""" # Load directly from YAML to check raw structure try: import yaml with open(annotation_path) as f: data = yaml.safe_load(f) tasks = data.get("tasks", []) total_candidates = 0 graded_candidates = 0 for task in tasks: candidates = task.get("candidates", []) total_candidates += len(candidates) for cand in candidates: if cand.get("relevance") is not None: graded_candidates += 1 # Also load via annotation_utils for processed annotations annotations = load_hand_annotations(annotation_path) except Exception as e: print(f"Warning: Could not load annotations: {e}") annotations = [] tasks = [] total_candidates = 0 graded_candidates = 0 stats = { "total_annotations": len(annotations), "total_candidates": total_candidates, "graded_candidates": graded_candidates, "has_similarity_type": 0, "has_is_substitute": 0, "has_role_match": 0, "has_archetype_context": 0, "has_format_context": 0, "has_substitution_quality": 0, "similarity_types": {}, "substitution_quality_dist": {}, "role_match_count": 0, "context_dependent_count": 0, } for ann in annotations: if ann.get("similarity_type") and ann["similarity_type"] != "unknown": stats["has_similarity_type"] += 1 st = ann["similarity_type"] stats["similarity_types"][st] = stats["similarity_types"].get(st, 0) + 1 if ann.get("is_substitute") is not None: stats["has_is_substitute"] += 1 if ann.get("role_match") is not None: stats["has_role_match"] += 1 if ann["role_match"]: stats["role_match_count"] += 1 if ann.get("archetype_context"): stats["has_archetype_context"] += 1 if ann["archetype_context"] != "universal": stats["context_dependent_count"] += 1 if ann.get("format_context"): stats["has_format_context"] += 1 if ann.get("substitution_quality"): stats["has_substitution_quality"] += 1 sq = ann["substitution_quality"] stats["substitution_quality_dist"][sq] = stats["substitution_quality_dist"].get(sq, 0) + 1 # Calculate percentages total = stats["total_annotations"] if total > 0: stats["pct_similarity_type"] = stats["has_similarity_type"] / total * 100 stats["pct_is_substitute"] = stats["has_is_substitute"] / total * 100 stats["pct_role_match"] = stats["has_role_match"] / total * 100 stats["pct_archetype_context"] = stats["has_archetype_context"] / total * 100 stats["pct_format_context"] = stats["has_format_context"] / total * 100 stats["pct_substitution_quality"] = stats["has_substitution_quality"] / total * 100 return stats def test_substitution_pairs_extraction(annotation_path: Path) -> dict[str, Any]: """Test extraction of substitution pairs with enhanced fields.""" annotations = load_hand_annotations(annotation_path) # Extract with different filters all_pairs = extract_substitution_pairs_from_annotations( annotations, min_similarity=0.0, require_substitute_flag=False, ) explicit_substitute_pairs = extract_substitution_pairs_from_annotations( annotations, min_similarity=0.8, require_substitute_flag=True, ) functional_pairs = [ ann for ann in annotations if ann.get("similarity_type") == "functional" and ann.get("is_substitute", False) ] return { "total_annotations": len(annotations), "all_pairs": len(all_pairs), "explicit_substitute_pairs": len(explicit_substitute_pairs), "functional_substitute_pairs": len(functional_pairs), } def main() -> int: parser = argparse.ArgumentParser(description="Test downstream tasks with enhanced annotations") parser.add_argument("--annotation", type=str, required=True, help="Annotation YAML file") parser.add_argument("--output", type=str, help="Output JSON report") args = parser.parse_args() annotation_path = Path(args.annotation) if not annotation_path.exists(): print(f"Error: Annotation file not found: {annotation_path}") return 1 print("=" * 70) print("ENHANCED ANNOTATION ANALYSIS") print("=" * 70) print() # Analyze enhanced fields stats = analyze_enhanced_annotations(annotation_path) print(f" Annotation Statistics:") print(f" Total annotations (processed): {stats['total_annotations']}") print(f" Total candidates (raw): {stats.get('total_candidates', 0)}") print(f" Graded candidates: {stats.get('graded_candidates', 0)}") print() print(f"ðŸ“‹ Enhanced Field Coverage:") print(f" similarity_type: {stats['has_similarity_type']}/{stats['total_annotations']} ({stats.get('pct_similarity_type', 0):.1f}%)") print(f" is_substitute: {stats['has_is_substitute']}/{stats['total_annotations']} ({stats.get('pct_is_substitute', 0):.1f}%)") print(f" role_match: {stats['has_role_match']}/{stats['total_annotations']} ({stats.get('pct_role_match', 0):.1f}%)") print(f" archetype_context: {stats['has_archetype_context']}/{stats['total_annotations']} ({stats.get('pct_archetype_context', 0):.1f}%)") print(f" format_context: {stats['has_format_context']}/{stats['total_annotations']} ({stats.get('pct_format_context', 0):.1f}%)") print(f" substitution_quality: {stats['has_substitution_quality']}/{stats['total_annotations']} ({stats.get('pct_substitution_quality', 0):.1f}%)") print() if stats["similarity_types"]: print(f"ðŸ“ˆ Similarity Type Distribution:") for st, count in sorted(stats["similarity_types"].items(), key=lambda x: -x[1]): print(f" {st}: {count}") print() if stats["substitution_quality_dist"]: print(f"ðŸ“ˆ Substitution Quality Distribution:") for sq, count in sorted(stats["substitution_quality_dist"].items(), key=lambda x: -x[1]): print(f" {sq}: {count}") print() print(f" Downstream Task Support:") print(f" Role matches: {stats['role_match_count']} (for deck completion)") print(f" Context-dependent: {stats['context_dependent_count']} (for contextual discovery)") print() # Test substitution pair extraction sub_stats = test_substitution_pairs_extraction(annotation_path) print(f" Substitution Pair Extraction:") print(f" All pairs: {sub_stats['all_pairs']}") print(f" Explicit substitutes: {sub_stats['explicit_substitute_pairs']}") print(f" Functional substitutes: {sub_stats['functional_substitute_pairs']}") print() # Save report if requested if args.output: report = { "annotation_file": str(annotation_path), "enhanced_field_stats": stats, "substitution_extraction": sub_stats, } with open(args.output, "w") as f: json.dump(report, f, indent=2) print(f"âœ“ Saved report to {args.output}") print("=" * 70) print(" Analysis complete!") print("=" * 70) return 0 if __name__ == "__main__": import sys sys.exit(main())
