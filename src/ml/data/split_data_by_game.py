#!/usr/bin/env python3 """ Split multi-game datasets into per-game files. Reads: - src/backend/pairs.csv (mixed games) - src/backend/decks_hetero.jsonl (mixed games) Writes: - data/pairs/magic_pairs.csv - data/pairs/pokemon_pairs.csv - data/pairs/yugioh_pairs.csv - data/decks/magic_decks.jsonl - data/decks/pokemon_decks.jsonl - data/decks/yugioh_decks.jsonl Game detection: - Load card databases from backend to identify game per card - Fallback heuristics: Pokemon has "Energy" cards, YGO has specific archetypes """ import json from collections import defaultdict from pathlib import Path import pandas as pd def load_game_card_sets(): """Load card names per game from backend data.""" games = {"magic": set(), "pokemon": set(), "yugioh": set()} # MTG: load from scryfall cards (zst compressed) scryfall = Path("src/backend/data-full/games/magic/scryfall/cards") if scryfall.exists(): import subprocess # Sample a few zst files and decompress to get card names for zst in list(scryfall.glob("*.json.zst"))[:100]: try: result = subprocess.run( ["zstd", "-d", "-c", str(zst)], capture_output=True, text=True, timeout=5, ) if result.returncode == 0: data = json.loads(result.stdout) if "name" in data: games["magic"].add(data["name"]) except Exception: continue # Pokemon: heuristic - cards with "Energy" or from limitless decks limitless = Path("src/backend/data-full/games/pokemon/limitless-web") if limitless.exists(): for zst in list(limitless.glob("*.json.zst"))[:100]: try: result = subprocess.run( ["zstd", "-d", "-c", str(zst)], capture_output=True, text=True, timeout=5, ) if result.returncode == 0: data = json.loads(result.stdout) # Extract card names from partitions for part in data.get("partitions", []): for card in part.get("cards", []): games["pokemon"].add(card.get("name", "")) except Exception: continue # YGO: from ygoprodeck tournament ygo = Path("src/backend/data-full/games/yugioh/ygoprodeck-tournament") if ygo.exists(): for zst in list(ygo.glob("*.json.zst")): try: result = subprocess.run( ["zstd", "-d", "-c", str(zst)], capture_output=True, text=True, timeout=5, ) if result.returncode == 0: data = json.loads(result.stdout) for part in data.get("partitions", []): for card in part.get("cards", []): games["yugioh"].add(card.get("name", "")) except Exception: continue return games def infer_game(card_name: str, game_sets: dict) -> str: """Infer game from card name using loaded sets and heuristics.""" # Exact match for game, cards in game_sets.items(): if card_name in cards: return game # Heuristics lower = card_name.lower() if "energy" in lower and not any(x in lower for x in ["kinetic", "entropic"]): return "pokemon" # Default to magic (most common) return "magic" def split_pairs(input_csv: str, output_dir: Path, game_sets: dict): """Split pairs.csv by game.""" print(f"Loading pairs from {input_csv}...") df = pd.read_csv(input_csv) print(f" {len(df)} pairs") # Infer game for each pair df["game1"] = df["NAME_1"].apply(lambda x: infer_game(x, game_sets)) df["game2"] = df["NAME_2"].apply(lambda x: infer_game(x, game_sets)) # Split by game (both cards must be same game) for game in ["magic", "pokemon", "yugioh"]: mask = (df["game1"] == game) & (df["game2"] == game) game_df = df[mask][["NAME_1", "NAME_2", "COUNT_SET", "COUNT_MULTISET"]] output_file = output_dir / f"{game}_pairs.csv" game_df.to_csv(output_file, index=False) print(f" {game}: {len(game_df)} pairs → {output_file}") # Cross-game pairs (for research) cross = df[df["game1"] != df["game2"]][["NAME_1", "NAME_2", "COUNT_SET", "COUNT_MULTISET"]] if len(cross) > 0: cross_file = output_dir / "cross_game_pairs.csv" cross.to_csv(cross_file, index=False) print(f" cross-game: {len(cross)} pairs → {cross_file}") def split_decks(input_jsonl: str, output_dir: Path, game_sets: dict): """Split decks_hetero.jsonl by game.""" print(f"\nLoading decks from {input_jsonl}...") outputs = { "magic": open(output_dir / "magic_decks.jsonl", "w"), "pokemon": open(output_dir / "pokemon_decks.jsonl", "w"), "yugioh": open(output_dir / "yugioh_decks.jsonl", "w"), } counts = defaultdict(int) with open(input_jsonl) as f: for line in f: obj = json.loads(line) cards = obj.get("cards", []) if not cards: continue # Infer game from first card first_card = cards[0].get("name", "") game = infer_game(first_card, game_sets) outputs[game].write(line) counts[game] += 1 for fh in outputs.values(): fh.close() for game, count in counts.items(): print(f" {game}: {count} decks → {output_dir / f'{game}_decks.jsonl'}") def main(): from ml.utils.paths import PATHS # Create output directories pairs_dir = PATHS.data / "pairs" decks_dir = PATHS.data / "decks" pairs_dir.mkdir(parents=True, exist_ok=True) decks_dir.mkdir(parents=True, exist_ok=True) print("="*60) print("SPLITTING MULTI-GAME DATA BY GAME") print("="*60) # Load game card sets print("\nLoading game card databases...") game_sets = load_game_card_sets() for game, cards in game_sets.items(): print(f" {game}: {len(cards)} cards loaded") # Split pairs print("\n" + "="*60) split_pairs("src/backend/pairs.csv", pairs_dir, game_sets) # Split decks print("\n" + "="*60) split_decks("src/backend/decks_hetero.jsonl", decks_dir, game_sets) print("\n" + "="*60) print(" SPLIT COMPLETE") print("="*60) print("\nNext steps:") print("1. Train per-game embeddings:") print(" uv run python card_similarity_pecan.py --input data/pairs/magic_pairs.csv --output magic_64d") print("2. Update API to load per-game models") print("3. Run per-game evaluation") if __name__ == "__main__": main()