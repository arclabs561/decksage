# Annotation Review - 2026-01-01

## Executive Summary

**Status**: Critical issues identified. Most annotation batches are empty, and LLM-generated annotations show suspicious patterns indicating low quality or automated defaults.

## Findings

### 1. Hand Annotations (YAML)

**Status**: 0% completion across all batches

| File | Queries | Candidates | Completion | Status |
|------|---------|------------|------------|--------|
| `hand_batch_magic_enhanced.yaml` | 60 | 900 | 0% | Empty |
| `hand_batch_pokemon.yaml` | 42 | 620 | 0% | Empty |
| `hand_batch_pokemon_enhanced.yaml` | 42 | 620 | 0% | Empty |
| `hand_batch_pokemon_retrofitted.yaml` | 42 | 620 | 0% | Empty |
| `hand_batch_yugioh.yaml` | 42 | 620 | 0% | Empty |
| `hand_batch_yugioh_enhanced.yaml` | 42 | 620 | 0% | Empty |
| `hand_batch_yugioh_retrofitted.yaml` | 42 | 620 | 0% | Empty |

**Total**: 312 queries, 4,620 candidates, 0 graded

**Only completed batch**: `batch_001_initial.yaml` (5 queries, 20 candidates, 100% complete)

### 2. LLM Annotations (JSONL)

**Status**: Low quality, suspicious patterns

#### `yugioh_llm_annotations.jsonl`
- **Total**: 50 annotations
- **Issues**:
  - All annotations have relevance=2 (no variation)
  - All annotations have similarity=0.5 (suspicious default)
  - All confidence scores are 0.7 (suspicious default)
- **Conclusion**: Likely automated defaults, not real judgments

#### `riftbound_llm_annotations.jsonl`
- **Total**: 3 annotations
- **Issues**:
  - All annotations have relevance=2
  - All annotations have similarity=0.5
- **Conclusion**: Too few samples, same pattern as Yu-Gi-Oh

### 3. LLM Judgments (JSON)

**Status**: Suspicious patterns

#### `judgment_20251001_105332.json`
- **Query**: Lightning Bolt
- **Evaluations**: 10 candidates
- **Issues**:
  - All evaluations have relevance=2 (no variation)
  - All candidates flagged for groupthink (suspicious)
  - All confidence scores are 1.0 (suspicious)
  - Only one method used (node2vec)
- **Conclusion**: Programmatic ensemble appears to be producing uniform outputs

## Quality Assessment

### Positive
1. **Schema and structure**: Well-defined schema (`schema.yaml`) with clear guidelines
2. **Initial batch**: `batch_001_initial.yaml` shows good quality manual annotations
3. **Tooling**: Good infrastructure for generating batches and grading
4. **Enhanced fields**: Enhanced batches include useful downstream task fields

### Critical Issues

1. **No hand annotations completed**: All 7 hand annotation batches are empty (0% completion)
2. **LLM annotation quality**: Uniform scores suggest defaults, not real judgments
3. **No inter-annotator agreement**: Only one annotator in initial batch
4. **Judgment system issues**: Programmatic judgments producing uniform outputs

## Recommendations

### Immediate Actions

1. **Complete hand annotations**: Start with one batch (e.g., `hand_batch_magic_enhanced.yaml`)
   - Focus on completing 10-20 queries first
   - Validate quality before scaling

2. **Fix LLM annotation generation**: Investigate why LLM annotations have uniform scores
   - Check `llm_annotator.py` for default value issues
   - Verify LLM API calls are actually being made
   - Add validation to reject uniform outputs

3. **Fix judgment system**: Investigate programmatic ensemble
   - Why are all candidates flagged for groupthink?
   - Why are all relevance scores 2?
   - Why is confidence always 1.0?

### Medium-term

1. **Inter-annotator agreement**: Get second annotator for validation
2. **Quality metrics**: Track completion rates and quality over time
3. **Validation pipeline**: Add automated checks for suspicious patterns

### Long-term

1. **Scale to 100+ queries**: As per README goals
2. **Multi-annotator validation**: For critical queries
3. **Continuous quality monitoring**: Track metrics over time

## Metrics Tracking

Current metrics file (`quality_2025_10_01.json`) shows:
- Only 5 queries completed (from initial batch)
- No inter-annotator agreement
- Baseline established but not expanded

## Next Steps

1. **Priority 1**: Complete at least one hand annotation batch (start with Magic, 10-20 queries)
2. **Priority 2**: Fix LLM annotation generation to produce varied, realistic scores
3. **Priority 3**: Investigate and fix judgment system uniform outputs
4. **Priority 4**: Set up quality monitoring to catch these issues earlier

## Tools Available

- `scripts/annotation/review_annotations.py`: Review all annotations (just created)
- `src/ml/annotation/hand_annotate.py grade`: Validate completion
- `src/ml/annotation/hand_annotate.py merge`: Merge to test sets

## Conclusion

The annotation infrastructure is well-designed, but execution is incomplete. Most batches are empty, and LLM-generated annotations show suspicious patterns. Focus should be on completing hand annotations and fixing LLM generation quality before scaling.
